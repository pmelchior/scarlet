{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Concepts\n",
    "\n",
    "The purpose of this guide is to explain the core concepts of *scarlet*, how they are used and how they can be extended and customized for more specialized science cases.\n",
    "\n",
    "Other resources are:\n",
    "\n",
    "1. Our [Quickstart Guide](0-quickstart.rst) shows a typical *scarlet* session.\n",
    "2. The [API Documentation](api/scarlet.rst) describes modules and classes of the python library.\n",
    "3. A more in-depth explaination of the mathematics and algorithms used by *scarlet* is in [Melchior et al. 2018](https://arxiv.org/abs/1802.10157)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The goal of *scarlet* is to create a model of individual astrophysical sources from a collection of observations of a rectangular region of the sky. These observations can be in multiple filter bands (which we will call \"channels\" internally) with different PSFs, from telescopes with different resolutions, and eventually even spectroscopic instruments.\n",
    "A main emphasis of *scarlet* lies in deblending overlapping sources. \n",
    "As is pointed out by Robert Lupton, perfect reconstruction of a blended scene is [impossible](https://docushare.lsst.org/docushare/dsweb/Services/Document-29071), however by making a few minor assumptions *scarlet* improves on other blending algorithms by leveraging as much data as possible.\n",
    "\n",
    "The basic assumption of *scarlet* is that sources in an astrophysical image can be thought of as a collection of `Component` instances, where each component has its own internal representation of the source properties (non-parameteric or parametric), from which it computes its model of the sources in a 3D hyper-spectral data cube of pixels vs wavelegths.\n",
    "A common model is `FactorizedComponent`, which describes the source as a non-parametric morphology image and an intensity in every channel (SED).\n",
    "With this ansatz, more complicated objects, like galaxies, can be thought of as a combination of multiple components (a `ComponentTree`), where components with different SEDs represent different populations of stars or gases in the host galaxy. To properly separate sources, further assumptions are required, for example that all of the flux is positive and that the spatial distribution stars and galaxies monotonically decreases from their centers.\n",
    "\n",
    "A `Frame` contains metadata for the hyperspectral cube *scarlet* seeks to construct as well as those describing an `Observation`. The latter is the combination of a `Frame` with several data units. Each observation can have multiple filter bands with a different PSF in each band that is internally matched to the model PSF.\n",
    "\n",
    "Into the model frame one or multiple `Component`s are inserted. Each of them can create a model of the hyperspectral data cube from its `Parameter`s. The recommended way of interacting with components is through the `source` classes.\n",
    "\n",
    "Finally, the `Blend` class links the sources with the observations and executes the optimization algorithm. \n",
    "\n",
    "For the most common type of source, we assume that the hyperspectral cube can be factorized into a 1D SED and a 2D morphology. Mathematically, the model of the scene is then\n",
    "\n",
    "$$\\mathsf{M}= \\sum_{k=1}^K \\mathsf{A}_k^T \\times \\mathsf{S}_k = \\mathsf{A}\\mathsf{S}, $$\n",
    "\n",
    "where $\\mathsf{A}_k \\in \\mathbb{R}^C$ is the SED and $\\mathsf{S}_k \\in \\mathbb{R}^N$ is the morphology of a single component in the model with $C$ channels and $N$ pixels in each channel.\n",
    "It is important to note that this so-called matrix factorization implies that SEDs and morphologies are independent, e.g. the SED of a component does not change over the region covered by its morphology.\n",
    "\n",
    "The scene is fit by minimizing the log-likelihood of the model, namely minimizing\n",
    "\n",
    "$$f(\\mathsf{A},\\mathsf{S}) \\propto \\frac{1}{2} || \\mathsf{Y}-\\mathsf{A}\\mathsf{S} ||_2^2, $$\n",
    "\n",
    "where $\\mathsf{Y}$ is a data cube and $||.||_2$ is the element-wise $L_2$ (Frobenius) norm. There is one such term for every observation.\n",
    "In detail, weights and other transformations like PSF convolutions also enter here, but as long as the noise is additive and Gaussian, the general form of a quadratic log-likelihood holds.\n",
    "\n",
    "Because there are often strong degeneracies between model components and their parameters, we exploit two mechanisms to stabilize the inference.\n",
    "\n",
    "* Every component parameter can specify a differentiable (log-)prior distribution.\n",
    "* Every component parameter can be constrained by non-differentiable penalties.\n",
    "\n",
    "Both options turn the inference of the maximum-likelihood estimate into a maximum a posteriori (MAP) estimate by minimizing\n",
    "$$f(\\mathsf{A}, \\mathsf{S}) + \\sum_{k=1}^K \\sum_{m=1}^{M_k} g^A_{km} \\left(\\mathsf{A}_{km} \\right) + g^S_{km} \\left(\\mathsf{S}_{km} \\right)$$\n",
    "\n",
    "\n",
    "While we optimize the log-likelihood and the log-prior by gradient descent, hard constraints are enforced through proximal operators; the curious reader will find more details in [Parikh & Boyd 2014](http://www.web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) and [Combettes & Pesquet 2011](https://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10).\n",
    "In short, proximal operators map an input vector to the nearest vector that satisfied the respective constraint. Many constraints/penalty functions have analytic proximal operators.\n",
    "The entire optimization uses the adaptive proximal gradient method (a non-smooth generalization of the popular Adam method) from the [proxmin](https://github.com/pmelchior/proxmin) package, described in [Melchior et al. 2019](https://arxiv.org/abs/1910.10094).\n",
    "\n",
    "The remainder of this document explains how to proceed from some observation to the model parameters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "`Observation`s are specified by some data, e.g. images in a number of bands, and their meta-data.\n",
    "Observational data is assumed to be standardized, i.e. multi-band image cubes are astrometrically corrected so that pixels line up across bands, and probably sky-background subtracted (unless you want to fit the sky as another component). We recommend not to perform PSF homogenization across bands as it reduces the information content of the observations. \n",
    "\n",
    "We also recommend specifying *all* necessary meta-data to avoid ambiguities or improper behavior.\n",
    "\n",
    "* `weights`: per pixel inverse variances. Masked pixels have weight 0.\n",
    "* `psf`: per channel point spread functions. Either an image or a function to generate the image in the native resolution of the data. The PSFs need to be spatially aligned between bands.\n",
    "* `channels`: list of channel names, e.g. `['g','r','i']` for a set of broad-band filters.\n",
    "* `wcs`: `astropy` compatible WCS information to make pixel positions to world coordinates.\n",
    "\n",
    "`Observation` can be sub-classed for special instrumental models (lower resolution, grism, etc). The key methods are `match` and `render`, which enable to map between the two different frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame\n",
    "\n",
    "A `Frame` describes the meta-data portion of `Observation` (minus `weights`). It encodes where the observations are located with respect to a more complete hyperspectral description of the sky, e.g. a multi-band postage stamp is a set of broad-band observations `['g','r','i']` in a small rectangular region of the sky.\n",
    "\n",
    "***scarlet* uses multiple frames: one for each observation and one for the description of the model space.** The latter encodes the \"more complete hyperspectral description of the sky\" mentioned above, and it is this model space that we seek to populate with source models. The model space must be able to reach the space of observations by surjective mappings. As an example, fitting two sets of observations with different filters, PSFs, and resolutions requires that the model space covers the full set of filters and has a PSF and a pixel scale that are at least as small as the smallest observed PSF and pixel scale.\n",
    "\n",
    "*scarlet* cannot decide for you how to choose the model frame, but there are some guidelines. In general, the model frame needs to be just \"wide\" enough to model any signal that you could possibly have observed. It should not be wider, otherwise you seek to constrain aspect of the model for which there is no information in the observations.\n",
    "\n",
    "* For broadband observations, the model channels should be the unique list of all filters.\n",
    "* The model PSF needs to be narrower than any observed PSF. We recommend using a Gaussian with about 1 pixel width (in units of the model pixels). It's fast to compute and prevents spatial undersampling of the model.\n",
    "* The model pixel scale should be small enough that no observation is undersampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "\n",
    "A source is a convenient interface to specify what should be added to a model scene. Think of it as a physical unit, such as a star (`PointSource`) or a galaxy (`ExtendedSource`). It is a subclass of `Component` or `ComponentTree` (a hierarchical ordering of components) with a recipe to initialize and constrain its `Parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarlet\n",
    "import inspect\n",
    "lines = inspect.getsource(scarlet.RandomSource)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple but prototypical implementation. The base class is `FactorizedComponent`, which uses the SED-Morphology factorization introduced earlier. Therefore, it needs to define these two as `Parameter`s, so that the fitter will know to optimize them. Each parameter has a step size during optimization and is constrained to have only positive (actually: non-negative) elements through a `Constraint`.\n",
    "\n",
    "In addition, the initialization can make use of an observation to find suitable initial values of the `sed` parameter. As good initialization usually leads to much better results, this is where you should use your own insight to come up with guesses and step sizes that are suitable for the problem. This is the reason why ***scarlet* implements `source` classes as the primary interface to create custom solutions** for special analysis problems. It is layered on top of `Component` to make customization easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend\n",
    "\n",
    "The central piece of *scarlet* is the `Blend` class. It connects the list of sources to the list of observations and provides the `fit` method, which adjusts the parameters of the sources to match the observations. The result is a MAP solution that maximizes the log-likelihood under specified priors and constraints, as well as an error estimate for every parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component\n",
    "\n",
    "`Component` is the base class for all objects that populate the model space. It generates a hyperspectral model for a list of parameters.\n",
    "\n",
    "Several model parameterizations are available:\n",
    "\n",
    "* `CubeComponent` is the simplest model. It specifies a free-form (often incorrectly called \"non-parametric\") description of the hyperspectral frame, or a subvolume of it. Every voxel is independent.\n",
    "* `FactorizedModel` uses the SED-Morphology factorization. Both of these can be free-form or described by some functional form.\n",
    "* `FunctionComponent` uses a free-form SED, but a functional form of the morphology, which allows for point-source or Sersic-type fitting.\n",
    "\n",
    "Most of these models can be restricted to subvolumes by specifying a bounding `Box`. Alternative parametrizations are entirely doable. Open an [issue](https://github.com/pmelchior/scarlet/issues) if you need help with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "Every component can declare its own parameters, which we can access by with the `parameters` property. To demonstrate, we load the sources from the [Quick Start Guide](0-quickstart.rst):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fp = open(\"hsc_cosmos_35.sca\", \"rb\")\n",
    "sources = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "for k,src in enumerate(sources):\n",
    "    print (\"Source {}: {}\".format(k, src.__class__.__name__))\n",
    "    for p in src.parameters:\n",
    "        print (\"  Parameter '{}', Shape {}\".format(p.name, p.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source 0 is a `PointSource`, parameterized by a SED and a center and a sed center. Source 1 has multiple components (each with a SED and a free-form morphology), the rest have a SED and morphology each.\n",
    "\n",
    "`Parameter` is a souped up `numpy` array. It has a value and a name, as well as additonal attributes that store a `prior` and `constraint` that were enforced during optimization; the typical `step` size during optimization; an estimate of the standard deviate `std`; and whether the parameter was held `fixed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources[0].parameters[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, several parameters have converged within relative changes of `e_rel=1e-3` (the default setting of `Blend.fit`), but others have not. The fitter will have complained about non-convergence...\n",
    "\n",
    "To demonstrate the use of the error estimate, we make a signal-to-noise map of the morphology of source 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = sources[5].parameters[1]\n",
    "plt.imshow(p / p.std)\n",
    "\n",
    "plt.colorbar(label='SNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNR map shows that the center region is well determined by the data. Note that this error estimate is purely statistical and does not include correlations between different parameters or different components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Size\n",
    "\n",
    "**For every parameter, *you* have to specify to typical size of steps the optimizer should take.** Picking small steps leads to slow convergence, while large step sizes may lead to no convergence at all!\n",
    "\n",
    "*scarlet* uses the `adaprox` method from `proxmin`, which expects step sizes to be set in units of the parameter. That makes them relatively transparent. For instance, if you want to optimize the center position and you expect it to be initialized within 1 pixel of its optimal position, a step size of 0.1 is reasonable. Often, relative steps sizes are effective if one does not know the absolute magnitude of the parameter beforehand. We offer the method `scarlet.relative_step` specifically for this purpose. Inspecting the parameter above, you can see that it in fact used this method, with a relative factor of 0.01, i.e. the fitting method makes steps that are 1% of the mean magnitude of the parameter.\n",
    "\n",
    "The step size can either be an ordinary number, or a function with the signature `step(X, it) -> float`, where `X` is the parameter itself, and the second argument is the iteration counter of the optimizer. It is possible to specify a step size *per element* of a parameter. Proceed at your own peril."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior\n",
    "\n",
    "`Prior` and `Constraint` bring in additional information, which helps with robust parameter inference, which is especially important for cases with strong parameter degeneracies. Blending inevitably yields such degeneracies.\n",
    "\n",
    "`Prior`s encode which values for a parameter are more likely. The optimimization adds the log-likelihood and the log-prior to find a MAP estimate.\n",
    "\n",
    "`Prior`s need to implement two methods:\n",
    "\n",
    "* `__call__(self, x)` returns the logarithm of the prior at the value `x` of the parameter\n",
    "* `grad(self, x)` returns the gradient of the logarithm of the prior at `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint\n",
    "\n",
    "`Constraint`s appear similar to `Prior`s, in that they describe prior information about valid parameter values. However, they differ in profound ways. A wide class of constraints are projections onto submanifolds of the parameter space, typically guided by theoretical knowledge or assumptions. Examples are the subspace of positive elements or the surface of a sphere. This means that solutions outside of the manifold are forbidden, while all solution on the manifold are equally acceptable. The transition between these two cases is generally non-differentiable. This requires a generalization of gradient-based optimizers to so-called sub-gradients, and the employment of proximal operators.\n",
    "\n",
    "`Constraint`s need to implement only one method: `__call__(self, x, step)` which returns the result of the proximal mapping for a parameter with value `x`. For projection operators, that amounts to the point on the desired manifold that is closest to `x` in the Euclidean metric. The argument `step` is the step size for the current gradient step, which is only used for some classes for proximal operators. Conveniently, projection operators *don't* use it.\n",
    "\n",
    "*scarlet* implements several proximal constraints, some of which we discuss below. In addition, L1 and L0 sparsity penalties are implemented. More can be added by exploiting analytical results e.g. in [Parikh & Boyd 2014](http://www.web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) and [Combettes & Pesquet 2011](https://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10). Open an [issue](https://github.com/pmelchior/scarlet/issues) for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positivity\n",
    "\n",
    "`PositivityConstraint` avoids the negative subspace. It performs the mapping $x\\rightarrow \\max(0, x)$ on every element of a parameter.\n",
    "\n",
    "### Normalization\n",
    "\n",
    "\n",
    "For `FactorizedComponent`, a fundamental degeneracy arises from the question which of the factors should capture the amplitude of the model. The overall flux could be stored in the SED or in the morphology, or some combination of both. The last option is degenerate.\n",
    "\n",
    "`NormalizationConstraint` allows to normalize the parameter, either to the sum of all elements or to the maximum element. In *scarlet*, we usually normalized the component morphology with `type='max'`, which can be very easily initialized without regarding the extent of the source. It results in the SED encoding color and intensity information. The advantage of this normalization is that two sources with similar colors can still be distinguished if they have different intensities.\n",
    "\n",
    "### Symmetry\n",
    "\n",
    "Many traditional models for fitting galaxies (Sersic, mixture-of-Gaussian, ...) implicitly employ this constraint, because most galaxies are in fact *largely* symmetric. For free-form models, demanding that astrophysical sources are symmetric reduces the number of effective degrees of freedom of the model by half. Using symmetry as a constraint has been used successfully in the SDSS deblender and also in our tests on substantially deeper HSC images. The proximal mapping for every symmetric pair of pixels $i,j$ is $x_i,x_j\\rightarrow\\tfrac{1}{2}(x_i + x_j)$.\n",
    "\n",
    "To make a source symmetric requires a position to make the model symmetric about. Source models are highy sensitive to this fractional pixel location so it is necessary to include an update function that estimates the position of a symmetric source in the blend. This operation is expensive, so the stability of this constraint needs to be weighed against the cost of enforcing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotonicity\n",
    "\n",
    "Another useful constraint from the SDSS-HSC deblender is the assumption that most astrophysical objects are monotonically decreasing from the peak.\n",
    "In detail, this assumption is incorrect e.g. for spiral galaxies, especially tightly wound ones.\n",
    "But we can build good representations of even complex galaxies as multiple stellar populations, each with a single SED and monotonically decreasing from its peak.\n",
    "\n",
    "We implemented three possible monotonic solutions in `MonotonicityConstraint`. Each of them restrict the intensity of the active pixel $i$ (blue) to at most the average of the pixel intensity of its direct neighbors in the direction of the source center (ochre):\n",
    "\n",
    "$$\n",
    "x_i\\leq\\frac{1}{N_i}\\sum_j^{N_i} w_j x_j\n",
    "$$\n",
    "\n",
    "| ![](images/nearest_ref.png) | ![](images/weighted_ref.png) |\n",
    "|:---------------------------:|:----------------------------:|\n",
    "| Nearest Neighbor            | Weighted Reference           |\n",
    "\n",
    "* `neighbor_weight='nearest'`: Only the neighbor that is closest to the center  defines the reference. This mode is the most flexible one but prone to creating radial \"spikes\".\n",
    "* `neighbor_weight='angle'`: All three neighbor pixels that are closer to the peak are combined to compute the reference intensity. The weights of the neighbor $w_j = \\cos(\\alpha_i - \\alpha_j)$, where $\\alpha_i$ and $\\alpha_j$ are the angles from the active and the neighbor pixel to the center, respectively. This option is a softened version of the nearest-neighbor weight but still prefers strong radial monotonicity and thus similarly prone to radial spikes.\n",
    "* `neighbor_weight='flat'`: All three neighbor pixels that are closer to the peak are combined with flat weights to compute the reference intensity. This option is the most restrictive and allows for the greatest degree of azimuthal smoothing.\n",
    "\n",
    "The monotonicity mapping hinges on a properly centered source, but in contrast to symmetry the center has to be localized only within one pixel.\n",
    "\n",
    "#### Implementation Note\n",
    "\n",
    "`MonotonicityConstraint` is implemented as a projection that is *not* a true proximal operator. It is possible to write monotonicity as a true proximal operator, but the implementation is far too slow for practical purposes. Instead, the morphology is projected into a space that has *a* monotonic solution, just not necessarily the closest one in the L2 sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Chains\n",
    "\n",
    "If multiple constraints should be simultaneously enforced, they can be organized in a `ConstraintChain`. We make use of the method of [Alternating Projections](https://en.wikipedia.org/wiki/Projections_onto_convex_sets), which finds a solution in the intersection of multiple submanifolds by sequentially projecting on every manifold. Normally, this process needs to be repeated multiple times to ensure that all constraints are being met. In practice, it is sufficient to repeat this process only once because the optimizer will require multiple iterations to finally converge, so in the vicinity of the final solution, multiple projections are in fact performed."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

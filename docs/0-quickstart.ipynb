{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n",
    "This tutorial shows how to quickly get started using *scarlet* to model an hyperspectral image cube. For a more in-depth introduction to *scarlet*, read the [Core Concepts](1-concepts.ipynb) or the [API Documentation](api/index.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a good colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno', interpolation='none', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load an example data set (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available, packages like [SEP](http://sep.readthedocs.io/) and [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one, but for this example we use part of the detection catalog generated by the [LSST DM stack](https://github.com/lsst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = np.load(\"../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "catalog = data[\"catalog\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.ImagePSF(data[\"psfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Image Cube\n",
    "This is an example of how to display an RGB image from an image cube of multiband data. In this case the image uses a $sinh^{-1}$ function to normalize the flux in each filter consistently to create an RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 0.2\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Frame and Observation\n",
    "\n",
    "A `Frame` in *scarlet* is a description of the hyperspectral cube of the model or the observations. Think of it as the metadata, what aspects of the sky are described here. At the least, a `Frame` holds the `shape` of the cube, for which we use the convention `(C, Ny, Nx)` for the number of elements in 3 dimensions: `C` for the number of bands/channels and `Ny, Nx` for the number of pixels at every channel.\n",
    "\n",
    "An `Observation` combines a `Frame` with several data units, similar to header-data arrangement in FITS files. In addition to the actual science image cube, you can and often must provide weights for all elements in the data cube, an image cube of the PSF model (one image for all or one for each channel), an `astropy.WCS` structure to translate from pixel to sky coordinates, and labels for all channels. The reason for specifying them is to enable the code to internally map from the model frame, in which you seek to fit a model, to the observed data frame."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "\n",
    "    It is crictical to realize that there are two frames: one for model that reconstructs the scene on the sky, and one for any observation of the scene. They may be identical, but mostly they are not, in which case the observation is an information-reduced rendering of the model. The loss of information could be in terms of signal-to-noise ratio, spatial resolution, PSF blurring, spectral coverage, or all of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we assume that bands and pixel locations are identical between the model and the observation. Because we have ground-based images with different PSFs in each band, we need to provide a reference PSF for the model. We simply choose a minimal Gaussian PSF that is barely well sampled as our reference kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psf = scarlet.GaussianPSF(sigma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psfs=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psfs=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last command calls the `match` method to compute e.g. PSF difference kernel and filter transformations.\n",
    "\n",
    "We generally recommend this pattern:\n",
    "1. define model frame\n",
    "2. construct observation\n",
    "3. match it to the model frame\n",
    "\n",
    "Steps 2 and 3 are combined above using a fluent pattern.\n",
    "\n",
    "## Initialize sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. We provide several pre-built source types:\n",
    "\n",
    "* `RandomSource` fit per-band amplitude and non-parametric morphology starting from uniform random draws for both.\n",
    "* `PointSource` fits centers and per-band amplitude using the observed PSF model.\n",
    "* `ExtendedSource` fits per-band amplitude and a non-parametric morphology (which can be constrained to be symmetric and/or monotonic with respect to the center).\n",
    "* `ExtendedSource(K=2)` splits an `ExtendedSource` into `K` components that are initially radially separated and stacked on top of each other like a pyramid.\n",
    "\n",
    "In our example, we assume *prior* knowledge that object 0 is a star, and object 1 should be modeled with two components. Everything else is assumed a single-component galaxy. **We generally recommend `ExtendedSource` as default** if additional information about the source is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 0:\n",
    "        new_source = scarlet.PointSource(model_frame, (src['y'], src['x']), observation)\n",
    "    elif k == 1:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation, K=2)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation)\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. warning::\n",
    "\n",
    "    Coordinates in *scarlet* are given in the C/numpy notation (y,x) as opposed to the more conventional mathematical (x,y) ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(100, e_rel=1e-4)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We could use `scarlet.display.show_scene` to render to entire scene, but it's instructive to see how the model and the comparison to observations is performed.\n",
    "First we load the model for the entire scene, render it in the observation frame, and compute its residuals. We then show model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model\n",
    "model = blend.get_model()\n",
    "# Render it in the observed frame\n",
    "model_ = observation.render(model)\n",
    "# Compute residual\n",
    "residual = images-model_\n",
    "\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,src in enumerate(blend):\n",
    "    if hasattr(src, \"center\"):\n",
    "        y,x = src.center\n",
    "        ax[0].text(x, y, k, color=\"w\")\n",
    "        ax[1].text(x, y, k, color=\"w\")\n",
    "        ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_model=True,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                             add_markers=False,\n",
    "                             add_boxes=True\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each source \"lives\" in a smaller box and is then placed into the larger scene. The model of object 0 assumes the simple Gaussian shape of the model PSF, which is the internal representation of a point source. Source 1 uses the freedom of the 2-compoent model to represent a slightly redder core; the difference in spectrum is clearly noticeable.\n",
    "\n",
    "### Measure Fluxes\n",
    "\n",
    "The color information in these plots stems from the per-band amplitude, which are computed from the hyperspectral model by integrating over the morphology. The source spectra plots in the right panels above have done exactly that. The convention of these fluxes is given by the units and ordering of the original data cube. In the case of multi-component sources, the fluxes of all components are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"----------------- {}\".format(filters))\n",
    "for k, src in enumerate(sources):\n",
    "    print (\"Source {}, Fluxes: {}\".format(k, scarlet.measure.flux(src)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other measurements (e.g. `centroid`) are also implemented. The measurement approach is also easily extendable. The source models are generated in the model frame (which is the best-fit representation of the full hyperspectral `Frame`), from which any measurement can directly be made without having to deal with noise, PSF convolution, overlapping sources, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Re-Use Model\n",
    "\n",
    "To preserve the model for posterity, individual sources or lists of sources can be serialized with the `pickle` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fp = open(\"hsc_cosmos_35.sca\", \"wb\")\n",
    "pickle.dump(sources, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "\n",
    "    We recommend to serialize sources or source lists instead of a blend because the latter would also serialize the observations. That is normally not desired and will bloat the pickled file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickled file can be reopened in the same way. Every source can be utilized as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"hsc_cosmos_35.sca\", \"rb\")\n",
    "sources_ = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "scarlet.display.show_scene(sources_, norm=norm, add_boxes=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we want to refit some data with this model, we have to recreate a `Blend` instance.\n",
    "\n",
    "We will now add two more sources to account for the largest residuals we have seen above. As we don't know their location accurately, we allow the fitter to shift/recenter the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two sources at their approximate locations\n",
    "model_frame_ = sources_[0].frame\n",
    "yx = (14., 44.)\n",
    "new_source = scarlet.ExtendedSource(model_frame_, yx, observation, shifting=True)\n",
    "sources_.append(new_source)\n",
    "yx = (42., 9.)\n",
    "new_source = scarlet.ExtendedSource(model_frame_, yx, observation, shifting=True)\n",
    "sources_.append(new_source)\n",
    "\n",
    "# generate a new Blend instance\n",
    "blend_ = scarlet.Blend(sources_, observation)\n",
    "# tighten relative change in likelihood for convergence\n",
    "blend_.fit(100, e_rel=1e-4)\n",
    "\n",
    "# show convergence of logL\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend_.loss), -blend_.loss[-1]))\n",
    "plt.plot(-np.array(blend_.loss), label='7+2 sources')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that logL is slightly higher than before. Let's have a look at the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources_, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the two new sources 7 and 8, and that most of the features are very similar to before. As expected, the residuals have visibly improved and are now dominated by a red-blue pattern in the center of source 1, which we already fit with 2 components. Maybe we should try with 3 ..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

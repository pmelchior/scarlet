{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Documetation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    `astropy`_, `matplotlib`_, and execution of the following initialization cell\n",
    "    are required to execute some of the code on this page.\n",
    "\n",
    ".. _matplotlib: https://matplotlib.org\n",
    ".. _astropy: http://www.astropy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "import scarlet.constraints as sc\n",
    "from scarlet.config import Config\n",
    "\n",
    "# Load the sample images\n",
    "data = np.load(\"../data/test_sim/data.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "\n",
    "# Load the detection catalog\n",
    "from astropy.table import Table as ApTable\n",
    "catalog = ApTable.read(\"../data/test_sim/true_catalog.fits\")\n",
    "bg_rms = np.array([20]*len(images))\n",
    "# Set the arcsinh color scaling object\n",
    "asinh = scarlet.display.Asinh(img=images, Q=50)\n",
    "\n",
    "# Display the sources\n",
    "def display_sources(sources, subset=None, combine=False, show_sed=True):\n",
    "    \"\"\"Display the data and model for all sources in a blend\n",
    "    \n",
    "    This convenience function is used to display all (or a subset) of\n",
    "    the sources and (optionally) their SED's.\n",
    "    \"\"\"\n",
    "    if subset is None:\n",
    "        # Show all sources in the blend\n",
    "        subset = range(len(sources))\n",
    "    for m in subset:\n",
    "        # Load the model for the source\n",
    "        src = sources[m]\n",
    "        model = src.get_model(combine=combine)\n",
    "        # Since a model can be generated for each component in a source,\n",
    "        # or all components can be combined into a single model,\n",
    "        # reshape the model if there is only a single component\n",
    "        if len(model.shape)==4:\n",
    "            components = model.shape[0]\n",
    "        else:\n",
    "            model = np.expand_dims(model, axis=0)\n",
    "\n",
    "        # Select the image patch the overlaps with the source and convert it to an RGB image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images[src.bb], filter_indices=[3,2,1], norm=asinh)\n",
    "\n",
    "        # Build a model for each component in the model\n",
    "        rgb = []\n",
    "        for _model in model:\n",
    "            # Convert the model to an RGB image\n",
    "            _rgb = scarlet.display.img_to_rgb(_model, filter_indices=[3,2,1], norm=asinh)\n",
    "            rgb.append(_rgb)\n",
    "\n",
    "        # Display the image and model\n",
    "        figsize = [6,3]\n",
    "        columns = 2\n",
    "        # Calculate the number of columns needed and shape of the figure\n",
    "        if show_sed:\n",
    "            figsize[0] += 3\n",
    "            columns += 1\n",
    "        if not combine:\n",
    "            figsize[0] += 3*(model.shape[0]-1)\n",
    "            columns += model.shape[0]-1\n",
    "        # Build the figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = [fig.add_subplot(1,columns,n+1) for n in range(columns)]\n",
    "        ax[0].imshow(img_rgb)\n",
    "        ax[0].set_title(\"Data\")\n",
    "        for n, _rgb in enumerate(rgb):\n",
    "            ax[n+1].imshow(_rgb)\n",
    "            if combine:\n",
    "                ax[n+1].set_title(\"Initial Model\")\n",
    "            else:\n",
    "                ax[n+1].set_title(\"Component {0}\".format(n))\n",
    "        if show_sed:\n",
    "            for sed in src.sed:\n",
    "                ax[-1].plot(sed)\n",
    "            ax[-1].set_title(\"SED\")\n",
    "            ax[-1].set_xlabel(\"Band\")\n",
    "            ax[-1].set_ylabel(\"Intensity\")\n",
    "        # Mark the current source in the image\n",
    "        y,x = src.center\n",
    "        ax[0].plot(x-src.bb[2].start, y-src.bb[1].start, 'wx', mew=2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this overview is to understand the basic structure of the *scarlet* package, present some of the most useful parameters for customizing scenes, and explain how to extend the use of *scarlet* for more specialized science cases.\n",
    "The [User Documentation](user_docs.rst) contains more detailed descriptions of the modules and classes used in *scarlet*, and a more rigorous overview of the mathematics and algorithms used by *scarlet* is described in [Moolekamp and Melchior 2018](https://arxiv.org/abs/1708.09066) and [Melchior et al. 2018](https://arxiv.org/abs/1802.10157).\n",
    "In the future we also expect to add a tutorial section to give examples of more specialized science cases.\n",
    "\n",
    "### Basic Structure\n",
    "\n",
    "*scarlet* is designed to separate sources in astrophysical images by assuming that each scene (or [Blend](blend.ipynb#scarlet.blend.Blend)) can be thought of as a collection of mutiple [Source](source.ipynb#scarlet.source.Source) objects.\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains all of the information about the scene, including  routines for fitting sources and generating models.\n",
    "Each [Source](source.ipynb#scarlet.source.Source) in a [Blend](blend.ipynb#scarlet.blend.Blend) can be made up of multiple components, where each component has a single morphology (shape) and uniform spectrum (or SED) with a set of [Constraint](constraints.ipynb#scarlet.constraints.Constraint) objects used to break degeneracies in the model.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    While the API has stablized slightly, the boundary between actions performed on an entire scene (Blend) and those performed inside a Source object is not always clear, so expect some minor API changes in the future in order to optimize the code and enable additional features. As such the descriptions in this section might also be updated in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "\n",
    "At present *scarlet* does not have the functionality to detect sources, so in addition to the original blended image, *scarlet* requires a catalog of source coordinates in the image.\n",
    "As we will see later, a pitfall of the internal fitting algorithms used by the deblender is that they are very sensitive to undetected sources.\n",
    "This means that complicated blends may require iteratively detecting and modeling a scene multiple times to ensure that all of the sources have been accounted for.\n",
    "It is possible that a future version of *scarlet* might include multiband detection, but for now the user must use a package like [SEP](http://sep.readthedocs.io/) or [photutils](https://photutils.readthedocs.io/en/stable/) to perform source detection.\n",
    "\n",
    "## [Sources](source.ipynb#scarlet.source.Source)\n",
    "\n",
    "The base [Source](#scarlet.source.Source) class requires an initial guess for the SED and morphology of each source (or a list of seds and morphologies if a source has mutliple components, eg. a bulge and a disk).\n",
    "For most general use cases neither the SED nor the morphology are known ahead of time, so a set of convenience classes, [PointSource](source.ipynb#scarlet.source.PointSource) and [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), exist to generate an initial morpholgy and SED for a source at a given location in the image.\n",
    "It is also possible for users to specify their own source types with custom initialization methods.\n",
    "\n",
    "### Initialization\n",
    "The simplest [Source](#scarlet.source.Source) can be created using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B, Ny, Nx = images.shape\n",
    "center = (Ny//2, Nx//2)\n",
    "# Get the SED at the location of the central pixel\n",
    "sed = np.expand_dims(scarlet.source.get_pixel_sed(images, center), axis=0)\n",
    "# Set the morphology such that only the central pixel has any intensity\n",
    "morph = np.zeros((Ny, Nx))\n",
    "morph[center] = 1\n",
    "src = scarlet.Source(sed=sed, morph_image=np.expand_dims(morph, axis=0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Note in the code above that coordinates in *scarlet* use the traditional C/numpy notation (y,x) as opposed to the mathematical (x,y) ordering. A common error when first starting out with *scarlet* is to mix the order of x and y in your catalog or source list, which can have adverse affects on the results of the deblender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that while sources will typically have a `center` (position) argument specified, more exotic objects like jets or optical artifacts may not have a well defined center, so the `center` (coordinates) of a source in the image is not required for a general [Source](#scarlet.source.Source) (however both [PointSource](source.ipynb#scarlet.source.PointSource) and [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) do require a center during initialization).\n",
    "Also note that the center required by *scarlet* is the *geometric centroid* of the source, not the flux weighted average position that (unfortunately) is misleadingly often refered to as the \"centroid\" in astronomy.\n",
    "\n",
    "In general, most sources will fit in some subspace of the full image, so it is useful to initialize the source in the smallest possible frame (or bounding box).\n",
    "When the entire blend is fit, the size of the frame is recalculated if `fix_frame` is `False` (the default value).\n",
    "However, setting `fix_frame` to `True` will prevent the source from growing in size, which may be desireable in certain use cases.\n",
    "\n",
    "Due to the nature of the symmetry and monotonicity constraints to be examined later, it is useful to recenter all of the sources periodically to null dipoles that occur when objects are even slightly mis-aligned.\n",
    "If there is a good reason to believe that the initial positions are correct (such as in simulations) or that fitting them will create undesirable behavior, it is possible to set `shift_center=0`, which will cause the position of the current source to remain fixed.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It is possible to fix the position of a single source while recentering other sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the [Source](#scarlet.source.Source) base class can be used to initialize a source, it is more common to initialize a source using an inherited class.\n",
    "For example, [PointSource](source.ipynb#scarlet.source.PointSource) creates a new source given a `center` position using the SED of the pixel at that location in each band with only that single pixel turned on in the morphology.\n",
    "A more useful initialization class is the [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), which initializes a source that is symmetric and monotonically decreasing about the peak `center` location.\n",
    "For example, to create a list of sources for every source in the input catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) has a few additional arguments to the [Source](#scarlet.source.Source) base class.\n",
    "It requires `img`, the image datacube used to initialize the SED and morphology, and the background level `bg_rms`.\n",
    "The background level is needed so that the frame (or bounding box) for the source can be made as compact as possible by trimming the box at the `bg_rms` noise level during initialization (however unless `fix_frame` is turned off, the box can be resized later if necessary.\n",
    "\n",
    "For creating your own custom source initialization methods, see [Custom Sources](#Custom-Sources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n",
    "### Introduction to constraints in *scarlet*\n",
    "Part of the utility of *scarlet* comes from it's ability to allow users to create custom constraints.\n",
    "A thorough mathematical and algorithmic explanation of how constraints are applied to sources in the model can be found in [Moolekamp and Melchior 2018](https://arxiv.org/abs/1708.09066) and [Melchior et al. 2018](https://arxiv.org/abs/1802.10157).\n",
    "What follows is a description of the data structures in *scarlet* needed to apply those constraints to the model and how they can be extended or customized by an end user, however the user is referred to those papers for an explanation of the notation.\n",
    "\n",
    "As described in the paper mentioned above, to allow both smooth and non-smooth (non-differentiable) constraints the underlying algorithm in *scarlet* uses proximal operators, which can be as simple as projections onto the constrained space or more complicated functions (for a good reference on proximal operators see [Parikh and Boyd 2014](http://www.web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) and the appendix in [Combettes and Pesquet 2011](https://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10)).\n",
    "*scarlet* allows for two different kinds of constraints: proximal operators that act on the likelihood ($prox_f(A)$ or $prox_f(S)$) and constraints that act on a different vector space accessed through a linear operator ($prox_g \\left(\\mathsf{L} \\cdot A_k \\right)$ or $prox_g \\left(\\mathsf{L} \\cdot S_k \\right)$.\n",
    "$prox_f$ constraints can be thought of as *strict* constraints, in that each step of the fitting algorithm will result in an update to the variable that obeys the constraint.\n",
    "Conversely, $prox_g$ constraints do not act on the variable directly and instead will converge to a solution that obeys the constraint, meaning intermediate steps might violate one or more of the constraints.\n",
    "Users should take this behavior into consideration before deciding which constraint to use.\n",
    "\n",
    "For example, the [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) is (by default) a symmetric and monotonic model.\n",
    "It has been our experience that using a prox$_g$ monotonicity constraint does not work well, as monotonicity is basically a radial gradient and if a single pixel disobeys the monotonicity constraint, pixels radially further from the peak can also be unnaturally high as they are technically monotonicaly decreasing from the single hot pixel.\n",
    "Instead, [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) implements a strict monotonicity projection that guarantees that the model is monotonic in every step.\n",
    "On the other hand, because most galaxies are not perfectly symmetric, it can be beneficial to have a symmetry constraint that is not strictly enforced in each step, so by default [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) has a prox$_g$ symmetry constraint.\n",
    "\n",
    "Constraints are added to individual components of sources via the [Constraint](constraints.ipynb#scarlet.constraints.Constraint) base class.\n",
    "A single [Constraint](constraints.ipynb#scarlet.constraints.Constraint) object can have mutliple different constraints, combined in a [ConstraintList](constraints.ipynb#scarlet.constraints.ConstraintList).\n",
    "\n",
    "For example, the [MinimalConstraint](constraints.ipynb#scarlet.constraints.MinimalConstraint), which requires the SED to have non-negative elements that sum to unity and the morphology to be non-negative, can be combined with an [L0Constraint](constraints.ipynb#scarlet.constraints.L0Constraint) using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = sc.MinimalConstraint() & sc.L0Constraint(0.1)\n",
    "constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the $prox_f$ constraints for the sed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_sed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows (as expected) that the sed must be positive and sum to unity.\n",
    "\n",
    "We also see that there are no prox_g constraints or linear operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(constraint.prox_g_sed)\n",
    "print(constraint.prox_g_morph)\n",
    "print(constraint.L_sed)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we get a surprise when we look at $prox_f$ for the morphology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_morph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because we have applied two different $prox_f$ constraints by \"daisy chaining\" them together.\n",
    "Because the different $prox_f$ constraints are not guaranteed to commute, the `proxmin.operators.AlternatingProjections` object alternates the order it applies each proximal operator or projection to make the solution more robust.\n",
    "Examining this object shows the two proximal operators it alternates between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_morph.operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (in theory) combine as many constraints as we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = constraint & sc.PositivityConstraint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, because the [PositivityConstraint](constraints.ipynb#scarlet.constraints.PositivityConstraint) applies both [prox_center_on](operators.ipynb#scarlet.operators.prox_center_on) (which forces the center pixel to have a small but non-zero value to prevent the recentering algorithm from crashing) and `proxmin.operators.prox_plus`, we get `proxmin.operators.prox_plus` twice, which is a waste of CPU time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_morph.operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to achieve the same result would be to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = sc.SimpleConstraint() & sc.L0Constraint(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where [SimpleConstraint](constraints.ipynb#scarlet.constraints.SimpleConstraint) inherits from [PositivityConstraint](constraints.ipynb#scarlet.constraints.PositivityConstraint) and adds `proxmin.prox_unit_plus` to `prox_sed`.\n",
    "So the above command adds [L0Constraint](constraints.ipynb#scarlet.constraints.L0Constraint) to `prox_morph` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(constraint.prox_sed)\n",
    "constraint.prox_morph.operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry\n",
    "\n",
    "Approximating astrophysical sources as symmetric objects was a clever insight made by the SDSS deblender, which is also used in the HSC and LSST software stacks until an optimized version of *scarlet* is implemented.\n",
    "The idea is that when neighboring objects are blended together, the flux (or lack thereof) on the side opposite the neighbor can be used to force it's symmetric partner to a lower flux value.\n",
    "In the case of the SDSS-HSC deblender this template is taken as an approximation to the actual morphology and the original image is re-weighted using the symmetrized templates.\n",
    "\n",
    "*scarlet* takes the idea of symmetry more seriously, as the templates generated for each sorce are considered *the* model of the object.\n",
    "In this regime symmetry is forced on the object, even in cases where a source might not be exactly symmetric (for example grand design spirals, irregular galaxies, or jets).\n",
    "We are currently working on an implementation that imposes a less strict penalty for breaking symmetry, but what follows is the current symmetry constraint in *scarlet*.\n",
    "\n",
    "Symmetry is implement as a $prox_g$ proximal operator, where a linear matrix $L=$[getSymmetryOp](transformations.ipynb#scarlet.transformations.getSymmetryOp) takes the difference between each pixel and it's symmetric partner and the proximal operator `proxmin.operators.prox_zero` forces the dual variable onto the perfectly symmetric space (where all symmetric pair differences are zero).\n",
    "As stated in the previous subsection, this constraint is not strictly met in any given iteration but will converge to a solution where the morphology is nearly symmetric.\n",
    "\n",
    "We can add this constraint to our previous `constraint` using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = constraint & sc.SymmetryConstraint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that our constraint has a `prox_g_morph` but still no `L_morph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(constraint.prox_g_morph)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the linear operator can't be built until the source is initialized (because it needs to know the shape of the morphology), which happens when a new [Source](#scarlet.source.Source) is created by calling [Source.set_constraints()](source.ipynb#scarlet.source.Source).\n",
    "If we initialize a source with this constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = scarlet.source.PointSource((catalog[\"y\"][0], catalog[\"x\"][0]),\n",
    "                                 img=images, shape=(15, 15),\n",
    "                                 constraints=constraint)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the linear operator has been created.\n",
    "\n",
    "### Monotonicity\n",
    "\n",
    "Another key insight of the SDSS-HSC deblender is the approximation that most astrophysical objects are roughly monotonically decreasing from the peak.\n",
    "Of course this is also violated in spiral galxies, especially ones that are tightly wound.\n",
    "But if we think of spirals as a single source made up of multiple components, each monotonically decreasing from it's peak with a single SED, we can build a model that is well representative of the full galaxy.\n",
    "This point of view has the added benefit that regions that are not monotonically decreasing in a galaxy are likely different stellar populations with (potentially) different SED's and should be treated as separate components anyway.\n",
    "\n",
    "Monotonicity in *scarlet* is implemented as both a $prox_f$ and $prox_g$ constraint, so we will look at each use to see their differences.\n",
    "The $prox_g$ implementation uses the [MonotonicityConstraint](constraints.ipynb#scarlet.constraints.MonotonicityConstraint) class to build a [getRadialMonotonicOp](transformations.ipynb#scarlet.transformations.getRadialMonotonicOp) linear operator that takes the differences between the flux in the reference pixels and the flux in the current pixel.\n",
    "If `use_nearest` is `True`, only a single reference pixel is used, the pixel that is nearest to the current pixel in line with the peak. Otherwise a weighted average of all pixels closer to the peak than the current pixel is used to allow for a smoother monotonic solution.\n",
    "\n",
    "| ![](images/nearest_ref.png) | ![](images/weighted_ref.png) |\n",
    "|:---------------------------:|:----------------------------:|\n",
    "| Nearest Neighbor            | Weighted Reference           |\n",
    "\n",
    "For the $prox_g$ implementation, the `proxmin.operators.prox_plus` proximal operator is used to project the result of the linear operator onto the space where all values are non-negative, ie. the monotonic space.\n",
    "But because this is not a strict operator, a single \"hot\" pixel will cast a shadow into the noise as all of the pixels using it as a reference are technically monotonic.\n",
    "\n",
    "In the following example, for simplicity we use the [PointSource](source.ipynb#scarlet.source.PointSource) class to create a source with a simple initial SED and morphology, but add both a [SymmetryConstraint](constraints.ipynb#scarlet.constraints.SymmetryConstraint) and a [MonotonicityConstraint](constraints.ipynb#scarlet.constraints.MonotonicityConstraint) to allow the model to converge to a monotonic solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (15,15), # initial shape of the bounding box\n",
    "    constraints=(\n",
    "        sc.SimpleConstraint() # sed sum to unity, all elements of SED and morph are non-negative\n",
    "        & sc.MonotonicityConstraint(use_nearest=True) # prox_g monotonicity\n",
    "        & sc.SymmetryConstraint() # prox_g symmetry\n",
    "    ),\n",
    ") for src in catalog]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a blended scene with all of the sources.\n",
    "We'll discuss the [Blend](blend.ipynb#scarlet.blend.Blend) class more later, but for now we just use it to run a few iterations to see $prox_g$ monotonicity in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "# For simplicity only show the first 3 peaks\n",
    "display_sources(sources, subset=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sources 1 and 2 look ok, we see that source 0 is clearly not monotonically decreasing from the center (although if you look closely neither is source 1).\n",
    "\n",
    "Now we'll use the direct $prox_f$ monotonicity, which is written in C++ and forces all of the pixels to be monotonically decreasing by starting at the center pixel and working radially outward to enforce monotonicity. This also comes in a weighted and nearest neighbor version, so for consistency we use the nearest neighbor monototonicity again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (15,15), # initial shape of the bounding box\n",
    "    constraints=(\n",
    "        sc.SimpleConstraint() # sed sum to unity, all elements of SED and morph are non-negative\n",
    "        & sc.DirectMonotonicityConstraint(use_nearest=True) # prox_f monotonicity\n",
    "        & sc.SymmetryConstraint() # prox_g symmetry\n",
    "    ),\n",
    ") for src in catalog]\n",
    "\n",
    "# Create the blend and display the sources\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "display_sources(sources, subset=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see significant improvement using the direct monotonicity, even though (for reasons beyond the scope of this document) it is not an exact proximal operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Sources\n",
    "\n",
    "Many users may require specialized features that are not implemented in the simple [Source](#scarlet.source.Source) classes defined in *scarlet*, so the framework is built to support different initialization schemes in the form of inherited classes.\n",
    "For example, the following code creates a simple bulge-disk model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BulgeDisk(scarlet.Source):\n",
    "    \"\"\"A galactic source with two components\n",
    "    \"\"\"\n",
    "    def __init__(self, center, img, config=None):\n",
    "        self.center = center\n",
    "        if config is None:\n",
    "            config = Config()\n",
    "        # Use the smallest cache size for the initial bounding box\n",
    "        shape = (config.source_sizes[0],) * 2\n",
    "        # Use the same constraints as the default `ExtendedSource`\n",
    "        constraints = (sc.SimpleConstraint() &\n",
    "                       sc.DirectMonotonicityConstraint(use_nearest=False) &\n",
    "                       sc.SymmetryConstraint())\n",
    "        # Initialize the SEDs and morphologies for both components\n",
    "        sed, morph = self.make_initial(img, shape)\n",
    "        # WARNING: Don't forget to initialize the `Source`, as there is a lot\n",
    "        # of internal initialization\n",
    "        super(BulgeDisk, self).__init__(sed, morph, center=center, constraints=constraints)\n",
    "\n",
    "    def make_initial(self, img, shape):\n",
    "        B, Ny, Nx = img.shape\n",
    "        # A small but non-zero number\n",
    "        tiny = 1e-10\n",
    "        # center_int is a property of a `Source` that returns the\n",
    "        # integer position of the coordinates\n",
    "        _y, _x = self.center_int\n",
    "\n",
    "        # Get the color of the center pixel\n",
    "        disk_sed = scarlet.source.get_pixel_sed(img, self.center_int)\n",
    "        # Turn on all of the pixels in the box for the disk\n",
    "        disk_morph = np.zeros(shape)\n",
    "        cy = shape[0] >> 1\n",
    "        cx = shape[1] >> 1\n",
    "        dy = shape[0] >> 2\n",
    "        dx = shape[1] >> 2\n",
    "        disk_morph[cy-dy:cy+dy+1, cx-dx:cx+dx+1] = max(img[:,_y,_x].sum(axis=0), tiny)\n",
    "        disk_morph = disk_morph.reshape(shape[0]*shape[1])\n",
    "\n",
    "        # Make the bulge SED redder (and normalize)\n",
    "        bulge_sed = disk_sed + np.linspace(-0.1, 0.1, B)\n",
    "        bulge_sed /= np.sum(bulge_sed)\n",
    "        # Turn on a single pixel for the bulge\n",
    "        bulge_morph = np.zeros(shape[0] * shape[1])\n",
    "        center_pix = bulge_morph.size // 2\n",
    "        bulge_morph[center_pix] = max(img[:,_y,_x].sum(axis=0), tiny)\n",
    "\n",
    "        # Combine the two components into an initial `sed` and `morph`\n",
    "        sed = np.array([bulge_sed, disk_sed])\n",
    "        morph = np.array([bulge_morph, disk_morph]).reshape(2, shape[0], shape[1])\n",
    "        return sed, morph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example a new bulge-disk model is initialized with only the central coordinates of the source and the image of the scene.\n",
    "The source is initialized with the smallest available source size (see [Configuration](#Configuration)) and uses the same constraints as an [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), namely symmetry, monotonicity, and an SED that sums to unity (see [Constraints](#Constraints)).\n",
    "The initial SED and morphology are defined in the `make_initial` method, which initializes the morphology with a disk component that is half the size of the initial bounding box and a bulge component, which is a single pixel slightly redder than the disk.\n",
    "Finally the parent [Source](source.ipynb#scarlet.source.Source) class is initialized."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    When creating a class inherited from `Source`, don't forget to initialize the `Source`.\n",
    "    `Source.__init__` performs the initialization and configuration of parameters necessary for accessing a sources SED and morphology and projecting them properly onto the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a list of sources with two components, initialized using the `BulgeDisk` class above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "display_sources(bd_sources, range(3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The morphology is not exactly a single central pixel for each bulge or a flat morphology for each disk in the final model, even though we initialized them that way.\n",
    "    This is because the code uses a linear interpolation to translate the model for a given source into the image and is necessary to fit source positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run *scarlet* for a few iterations we see that the two components have begun to converge toward two separate solutions, although a second component doesn't appear to be necessary for any of these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "blend.fit(100)\n",
    "display_sources(blend.sources, range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blended Scenes\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains the entire blended scence.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "A number of global configuration options, used by both [Blend](blend.ipynb#scarlet.blend.Blend) and [Source](#scarlet.source.Source) objects, are accessed through the [Config](config.ipynb#scarlet.config.Config) class, making it easier to pass configuration options between a [Blend](blend.ipynb#scarlet.blend.Blend) and it's sources.\n",
    "See [Configuration](config.ipynb#Configuration-(scarlet.config)) for a detailed description of different configuration options.\n",
    "\n",
    "Most of the properties can be modified by the user on the fly, but changing the `Config.source_sizes` propery should be accomplished by using the [Config.set_source_sizes](config.ipynb#scarlet.config.Config.set_source_sizes) method, which ensures that all of the `source_sizes` are valid (see [Config](config.ipynb#scarlet.config.Config) for more).\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Initializing a new blended scene requires a list of `sources` ([Source](#scarlet.source.Source) objects), an image (`img`) datacube with dimensions (`bands`, `height`, `width`).\n",
    "If a weightmap exists, the user can also pass a `weights` datacube with the same dimensions as `img`.\n",
    "It is also useful to pass a value for the background RMS (`bg_rms`), which is used to minimize the box size needed for each source (see the discussion in [Resizing Sources](#Resizing-Sources)).\n",
    "Finally an optional [Config](config.ipynb#scarlet.config.Config) class can be specified, with custom configuration options.\n",
    "If no `config` is given, a new [Config](config.ipynb#scarlet.config.Config) instance is created using the default values.\n",
    "\n",
    "For most users, a good place to start is by defining each source as an [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) and initializing a blend with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a scene with a collection of sources, each one with a single SED and a morphology that is both monotonic and symmetric (see [Sources](#Sources)), and will use `bg_rms` to minimize the box sizes of each source.\n",
    "\n",
    "To customize the configuration of the [Blend](blend.ipynb#scarlet.blend.Blend), for example using a lower flux threshold for resizing source bounding boxes, a [Blend](blend.ipynb#scarlet.blend.Blend) can be initialized with a new [Config](config.ipynb#scarlet.config.Config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = Config(edge_flux_thresh=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will resize the box as long as flux greater than `Config.edge_flux_thresh*bg_rms`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    A number of internal properties are set when a new `Blend` is created, so it is important for the user to treat all properties of a `Blend` as private members.\n",
    "    For example, during initialization the list of `sources` is used to set the number of sources, components, and indices to lookup sources and components by the fitting algorithm are set.\n",
    "    If it is necessary to add additional sources at a later time, for example when using an iterative detection and deblending scheme for a more crowded field, it is best to create a new `Blend` using the new source list, otherwise internal data structures based on the initial list of sources could become corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Individual Sources and Components\n",
    "\n",
    "The bSDMM algorithm implemented by the [proxmin](https://github.com/pmelchior/proxmin) package expects A and S to be 2D matrices, however duck typed class are used to make more complicated tensors act as if they were 2D matrices.\n",
    "Internally the algorithm operates on the space of components, not sources (where a single [Source](#scarlet.source.Source) might have multiple components), so a [Blend](blend.ipynb#scarlet.blend.Blend) contains a number of indexing properties to convert from component space to source space.\n",
    "\n",
    "For example, a `blend` created using the `BulgeDisk` class has two components for each source, for a total of 2$\\times$sources components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "print(\"Number of sources:\", len(blend.sources))\n",
    "print(\"Number of components:\", blend.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we iterate through the sources we can find the index of the component in `blend`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m, src in enumerate(blend.sources):\n",
    "    for l in range(src.K):\n",
    "        k = blend.component_of(m,l)\n",
    "        print(\"Component {0} has index {1}\".format((m,l),k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the index of the model component $k$ to find the index of the source, and the index of the component inside that source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(blend.K):\n",
    "    m,l = blend.source_of(k)\n",
    "    print(\"Component {0} is component {1} in source {2}\".format(k, l, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Blend](blend.ipynb#scarlet.blend.Blend) also has a `__len__` method, so taking the length of `blend` gives the number of sources (not components):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Model\n",
    "\n",
    "Most of the internal methods of the [Blend](blend.ipynb#scarlet.blend.Blend) class are used to implement the minimization algorithm described in [Moolekamp and Melchior 2018](https://arxiv.org/abs/1708.09066).\n",
    "Below is a very brief summary of the method to elucidate how constraints are implemented in *scarlet*.\n",
    "\n",
    "The basic deblending algorithm builds a model\n",
    "\n",
    "$$M= \\sum_{k=1}^K A_k^T \\times S_k = AS, $$\n",
    "\n",
    "where $A_k \\in \\mathbb{R}^B$ is the normalized SED and $S_k \\in \\mathbb{R}^N$ is the morphology of a single component in the model with $B$ bands and $N$ pixels in each band.\n",
    "\n",
    "The blend is fit by minimizing the likelihood of the model, namely minimizing\n",
    "\n",
    "$$f(A,S) = \\frac{1}{2} || Y-AS ||_2^2, $$\n",
    "\n",
    "where $Y$ is the data (image) and $||.||_2$ is the element-wise $L2$ (Frobenius) norm.\n",
    "\n",
    "Constraints are applied to each source in the form of proximal operators, a handy mathematical tool for imposing non-smooth constraints that (if properly formulated) are guaranteed to converge.\n",
    "Each component $j$ can have multiple constraints $M_j$, this is equivilent to minimizing\n",
    "\n",
    "$$f(A, S) + \\sum_{j=1}^K \\sum_{i=1}^{M_j} g_{ji} \\left(Z_{ji} \\right)$$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$L_{ji} S_j - Z_{ji} = 0 \\ \\forall\\ j \\in \\{1, \\dotso, K \\} \\textrm{and } i\\in \\{1, \\dotso, M_j\\},$$\n",
    "\n",
    "where $K$ is the number of components, $g_{ji}$ is a constraint and $L_{ji}$ is a linear operator for the $i$th constraint of the $j$th component, and $Z_{ji}$ is a dual variable used to apply the constraint using the Block-Simultaneous Method of Multipliers (bSDMM, [Moolekamp and Melchior 2018](https://arxiv.org/abs/1708.09066)).\n",
    "\n",
    "While the details of the algorithm are not important for using *scarlet*, users interested in customizing the deblender for specific science cases will find it helpful to understand how $A$ and $S$ are updated, namely:\n",
    "\n",
    "$$ x^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\lambda f} \\left( x^{\\textrm{it}} - \\frac{\\lambda}{\\rho} \\mathsf{L}^T \\left( \\mathsf{L} x^{\\textrm{it}}-z^{\\textrm{it}} + u^{\\textrm{it}} \\right) \\right)$$\n",
    "\n",
    "$$z^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\rho g} \\left( \\mathsf{L} x^{\\textrm{it}+1} + u^{\\textrm{it}} \\right)$$\n",
    "\n",
    "$$u^{\\textrm{it}+1} \\leftarrow u^{\\textrm{it}} + \\mathsf{L} x^{\\textrm{it}+1} - z^{\\textrm{it}+1}$$\n",
    "\n",
    "where $x^{\\textrm{it}}$ is either $A_k$ or $S_k$ in the current iteration, $\\lambda$ and $\\rho$ are step sizes for $\\textrm{prox}_f$ and $\\textrm{prox}_g$, $z^{\\textrm{it}}$ is the dual variable in the current iteration, and $u^{\\textrm{it}}$ is the running difference between the constrained and current values of $\\mathsf{L} x$.\n",
    "\n",
    "The [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method is used to fit the current model and requires only two parameters: the maximum number of `steps` (or iterations) used to fit the data and the relative error for convergence (`e_rel`).\n",
    "[Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) builds the appropriate objects and calls `proxmin.algorithms.bsdmm` to fit the data, which will run until one of the following conditions is met:\n",
    "\n",
    "1. The total number of iterations is equal to `steps`\n",
    "\n",
    "1. The model converges (as defined in  [Moolekamp and Melchior 2018](https://arxiv.org/abs/1708.09066)).\n",
    "\n",
    "1. The algorithm throws a [ScarletRestartException](blend.ipynb#scarlet.blend.ScarletRestartException). This occurs when some variable is modified that is incompatible with continued execuation of `proxmin.algorithms.bsdmm`, usually the size or shape of at least one [Source](source.ipynb#scarlet.source.Source).\n",
    "\n",
    "1. The algorithm crashes for some other uncaught reason. We have attempted to generate useful error messages for common failure modes but new users are likely to find edge cases that we have not yet caught.\n",
    "\n",
    "If `proxmin.algorithms.bsdmm` exists due to a [ScarletRestartException](blend.ipynb#scarlet.blend.ScarletRestartException) and the total number of iterations (`it`) is less than `steps`, the sources are re-initialized and `proxmin.algorithms.bsdmm` is executed for `steps-it` iterations.\n",
    "In other words, even if the algorithm has to restart, [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) will never run for more than `steps`.\n",
    "\n",
    "### Restarting a Fit\n",
    "\n",
    "There may be instances where it is desirable to restart a fit.\n",
    "For example, after a certain number of iterations you might want to add or remove new sources, or you may have a custom constraint that you want to apply every Nth iteration.\n",
    "In that case you can call `Blend.fit(N)`, perform your cut, and restart for another `Blend.fit(N)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(20)\n",
    "print(blend.it)\n",
    "blend.fit(20)\n",
    "print(blend.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that blend is now on iteration `2*N`, with `N=20` in the example above.\n",
    "\n",
    "### Resizing Sources\n",
    "\n",
    "In most blends the number of non-zero pixels is $\\ll$ than the total number of pixels in the image.\n",
    "To save processing time we recommend initializing sources with a minimal number of pixels and allowing the [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method to expand the size of the box if necessary by calling the [Blend.resize_sources](blend.ipynb#scarlet.blend.Blend.resize_sources) method.\n",
    "This method uses the update for each source's morphology to determine if the bounding box for a source needs to be increased (which happens when the morphology has any flux above `config.edge_flux_thresh*blend.bg_rms` outside it's current bounding box).\n",
    "\n",
    "### Recentering Sources\n",
    "\n",
    "Due to the default [symmetry](#Symmetry) and [monotonicity](#Monotonicity) constraints, the model is dependent on the accuracy of the center position for each source.\n",
    "If the center is off by a fraction of a pixel then both monontonicy and symmetry force the model away from the data and can cause large residuals in the resulting model.\n",
    "The [Blend.recenter_sources](blend.ipynb#scarlet.blend.Blend.recenter_sources) method recenters all of the sources simultaneously by constructing a difference image, a copy of the current model shifted by an additional `Source.shift_center` pixels (usually a small number around 0.2).\n",
    "The function then simultaneously calculates the shift needed to align the models with the data to null any positional dipoles.\n",
    "\n",
    "Both resizing sources and recentering sources are expensive operations (as resizing requires rebuilding all of the constraint operators and recentering requires inverting all of the models in the original image) and are only performed every `Config.refine_skip` iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading and Displaying a Model\n",
    "\n",
    "### Display functions\n",
    "\n",
    "The [display](display.ipynb) module contains a number of convenience methods to convert an image cube into an RGB image array.\n",
    "\n",
    "There are two stock classes used to scale the pixels in the image, [Linear](display.ipynb#scarlet.display.Linear) and [Asinh](display.ipynb#scarlet.display.Asinh), both of which inherit from the `matplotlib.colors.Normalize` class.\n",
    "This inheritance allows them to be used as normalizations in `matplotlib.pyplot.imshow`, including an `inverse` method that makes it possible to add a colorbar.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Linear](display.ipynb#scarlet.display.Linear) class is fairly straightforward, allowing the user to (optionally) pass `vmin` and `vmax` parameters to set the range of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(vmin=0, vmax=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Asinh](display.ipynb#scarlet.display.Asinh) scaling is popular because it is linear for small values and logrithmic for larger fluxes, allowing it to display a wide range of intensities clearly.\n",
    "The actual formula used to scale each pixel is\n",
    "\n",
    "$$f(x) = \\frac{1}{Q} \\sinh^{-1} \\left( Q \\frac{x-v_\\textrm{min}}{v_\\textrm{max}-v_\\textrm{min}} \\right)$$\n",
    "\n",
    "where `Q` is a parameter that defines the strech of the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=10)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image cube can be converted from a (bands, height, width) array into an RGB image array using the [img_to_rgb](display.ipynb#scarlet.display.img_to_rgb) function.\n",
    "This allows the user to specify a normalization (`norm`), `fill_value` (value to use for any masked pixels), and list of indices to map to R, G, B respectively (`filter_indices`).\n",
    "For example the default is to map the first three bands in reverse order to RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the mapping is $r \\rightarrow R$, $g \\rightarrow G$, $u \\rightarrow B$.\n",
    "A more natural mapping (and the one used in most of this document) is $i \\rightarrow R$, $r \\rightarrow G$, $g \\rightarrow B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Blend\n",
    "\n",
    "You can load the models that make up a scene at any time, even if the blend has been initialized but not fit for a single iteration. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the blend but don't fit the model\n",
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to load the model for each source individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = blend.get_model(\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    flat=False # Don't flatten the model, keeping each component separate\n",
    ")\n",
    "img_rgb = scarlet.display.img_to_rgb(models[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even by component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a model \n",
    "model = blend.get_model(\n",
    "    m=0, # index of the first source\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    combine_source_components=False # Don't combine the components into a single model for each source\n",
    ")\n",
    "# Display the bulge\n",
    "img_rgb = scarlet.display.img_to_rgb(model[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()\n",
    "# Display the disk\n",
    "img_rgb = scarlet.display.img_to_rgb(model[1], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also want to extract just the morphology (without convolving with the SED). To prevent unexpected results (i.e. the model having a different shape depending on the given parameters) the resulting model will still have the shape (`components`, `bands`, `height`, `width`), however there are only `components` different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a few iterations, jsut to make the model more interesting\n",
    "blend.fit(100)\n",
    "model = blend.get_model(\n",
    "    m=0, # index of the first source\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    combine_source_components=False, # Don't combine the components into a single model for each source\n",
    "    use_sed=False # Don't convolve with the SED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(model[0][1])\n",
    "plt.show()\n",
    "plt.imshow(model[0][3])\n",
    "plt.show()\n",
    "plt.imshow(model[1][1])\n",
    "plt.show()\n",
    "plt.imshow(model[1][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Source\n",
    "\n",
    "It is also possible to access the morphology of a given source directly, which is always centered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = blend.sources[0]\n",
    "plt.imshow(src.image[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(src.image[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `src.image` is the same as `src.morph.reshape(src.K, src.Ny, src.Nx)`.\n",
    "Notice how in this space only the part of the model inside the bounding box is given, since this is the space where the morphology lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the SED for each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m, src in enumerate(blend.sources):\n",
    "    # Only display the SED for the bulge components\n",
    "    plt.plot(src.sed[0], label=m)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to extract the model for a given source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = src.get_model()\n",
    "_model = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = src.get_model(combine=False)\n",
    "_model = scarlet.display.img_to_rgb(model[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or without recentering  or PSF convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gamma = src._gammaOp([0,0], src.shape)\n",
    "model = src.get_model(Gamma=Gamma)\n",
    "_model = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because the `Source._gammaOp` is an operator that handles psf convolution and translation. This part of the code is likely to change in the near future, so we won't give a detailed description of how this is implementd in the code. But basically, `Source._gammaOp([dy,dx])` performs a psf convolution (if a psf was specified) and a linear shift by $dx$ and $dy$, the fraction of a pixel to move in the $x$ and $y$ directions respectively.\n",
    "\n",
    "## Other Useful Source Properties\n",
    "\n",
    "Below are a list of properties that can be accessed for a source. For more information about them, see [Source](source.ipynb#scarlet.source.Source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = blend.sources[1]\n",
    "print(\"Source shape:\", src.shape)\n",
    "print(\"Source dimensions:\", (src.Ny, src.Nx))\n",
    "print(\"Center:\", src.center)\n",
    "print(\"integer center:\", src.center_int)\n",
    "print(\"Slice of the original image to fit the source:\", src.get_slice_for(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the image centered on the source, where `Source.bb` is the bounding box to extract the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_img = images[src.bb]\n",
    "img_rgb = scarlet.display.img_to_rgb(_img, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a source is on the edge then it might be necessary to extract only part of the full source using [Source.get_slice_for](source.ipynb#scarlet.source.Source.get_slice_for), where `source.image[source.get_slice_for(images.shape)]` is the same shape and aligned with `images[source.bb]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "ax = [fig.add_subplot(1,2,1+n) for n in range(2)]\n",
    "ax[0].imshow(img_rgb)\n",
    "_img = scarlet.display.img_to_rgb(src.get_model()[src.get_slice_for(images.shape)], filter_indices=[3,2,1], norm=asinh)\n",
    "ax[1].imshow(_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the overview. The user is referred to the [User Documentation](user_docs.rst) for more details about the objects used in *scarlet*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

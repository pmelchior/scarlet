{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n",
    "This tutorial shows how to quickly get started using *scarlet* to model an hyperspectral image cube. For a more in-depth introduction to *scarlet*, read the [Core Concepts](concepts.ipynb) or the [API Documentation](api/index.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import logging\n",
    "logger = logging.getLogger('scarlet')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(\"proxmin\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "import autograd.numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and display data\n",
    "\n",
    "We load an example data set (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available packages like [SEP](http://sep.readthedocs.io/) and [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one, but for this example we use part of the detection catalog generated by the [LSST DM stack](https://github.com/lsst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = np.load(\"../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "catalog = data[\"catalog\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.PSF(data[\"psfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a raw image cube\n",
    "This is an example of how to display an RGB image from an image cube of multiband data. In this case the image uses a $sinh^{-1}$ function to normalize the flux in each filter consistently to create an RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping\n",
    "\n",
    "stretch = 0.1\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model frame and observation\n",
    "\n",
    "A `Frame` in *scarlet* is a description of the hyperspectral cube of the model or the observations. Think of it as the metadata, what aspects of the sky are described here. At the least, a `Frame` holds the `shape` of the cube, for which we use the convention `(C, Ny, Nx)` for the number of elements in 3 dimensions: `C` for the number of bands/channels and `Ny, Nx` for the number of pixels at every channel.\n",
    "\n",
    "An `Observation` combines a `Frame` with several data units, similar to header-data arrangement in FITS files. In addition the the actual science image cube, you can and often must provide weights for all elements in the data cube, an image cube of the PSF model (one image for all or one for each channel), an `astropy.WCS` structure to translate from pixel to sky coordinates, and labels for all channels. The reason for specifying them is to enable the code to internally map from the model frame, in which you seek to fit a model, to the observed data frame."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It crictical to realize that there are two frames: one for model that reconstructs the scene on the sky, and one for any observation of the scene. They may be identical, but mostly they are not, in which case the observation is an information-reduced rendering of the model. The loss of information could be in terms of signal-to-noise ratio, spatial resolution, PSF blurring, spectral coverage, or all of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we assume that bands and pixel locations are identical between the model and the observation. Because we have ground-based images with different PSFs in each band, we need to provide a reference PSF for the model. We simply choose a minimal Gaussian PSF that is barely well sampled as our reference kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the :class:`~scarlet.frame.Frame` and :class:`~scarlet.observation.Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psf=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psf=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last command calls the `match` method to compute e.g. PSF difference kernel and filter transformations.\n",
    "\n",
    "We generally recommend this pattern:\n",
    "1. define model frame\n",
    "2. construct observation\n",
    "3. match it to the model frame\n",
    "\n",
    "Steps 2 and 3 are combined above using a fluent pattern.\n",
    "\n",
    "## Initialize sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. We provide several pre-built source types:\n",
    "\n",
    "* `RandomSource` fit per-band amplitude and non-parametric morphology starting from uniform random draws for both.\n",
    "* `PointSource` fits centers and per-band amplitude using the observed PSF model.\n",
    "* `ExtendedSource` fits per-band amplitude and a non-parametric morphology (which can be constrained to be symmetric and/or monotonic with respect to the center).\n",
    "* `MultiComponentSource` splits an `ExtendedSource` into multiple components that are initially radially separated.\n",
    "\n",
    "In our example, we assume *prior* knowledge that object 0 is a star, and object 1 should be modeled with two components. Everything else is assumed a single-component galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 0:\n",
    "        new_source = scarlet.PointSource(model_frame, (src['y'], src['x']), observation)\n",
    "    elif k == 1:\n",
    "        new_source = scarlet.MultiComponentSource(model_frame, (src['y'], src['x']), observation, symmetric=False, monotonic=True, thresh=5)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation, symmetric=False, monotonic=True, thresh=5)\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Coordinates in *scarlet* are given in the C/numpy notation (y,x) as opposed to the more conventional mathematical (x,y) ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit model\n",
    "The `Blend` class represent the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(blend.loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the full model\n",
    "First we load the model for the entire scene, render it in the observation frame, and compute its residuals. We then show model and date with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)\n",
    "residual = images-model_\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,component in enumerate(blend):\n",
    "    y,x = component.center\n",
    "    ax[0].text(x, y, k, color=\"w\")\n",
    "    ax[1].text(x, y, k, color=\"w\")\n",
    "    ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the source models\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame. In this example, the two frames differ by an extra convolution from the minimal `model_psf` to the observed psfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stretch based on the model\n",
    "stretch = .3\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "\n",
    "for k,src in enumerate(sources):\n",
    "    # Get the model for a single source\n",
    "    model = src.get_model()\n",
    "    model_ = observation.render(model)\n",
    "    \n",
    "    # Convert observation and models to RGB\n",
    "    img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "    model_rgb = scarlet.display.img_to_rgb(model, norm=norm)\n",
    "    model_rgb_ = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "\n",
    "    # Set the figure size\n",
    "    ratio = src.frame.shape[2]/src.frame.shape[1]\n",
    "    fig_height = 3*src.frame.shape[1]/20\n",
    "    fig_width = max(2*fig_height*ratio,2)\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Generate and show the figure\n",
    "    ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[0].set_title(\"Data\")\n",
    "    ax[1].imshow(model_rgb_)\n",
    "    ax[1].set_title(\"Observed model {0}\".format(k))\n",
    "    ax[2].imshow(model_rgb)\n",
    "    ax[2].set_title(\"Model {0}\".format(k))\n",
    "    # Mark the source in the data image\n",
    "    y,x = src.center\n",
    "    ax[0].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    ax[1].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    ax[2].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model of object 0 assumes the simple Gaussian shape of the model PSF, which is the internal representation of a point source. Source 1 uses the freedom of the 2-compoent model to represent a slightly redder core.\n",
    "\n",
    "### Measure Fluxes\n",
    "\n",
    "The color information in these plots stems from the per-band amplitude, which could be obtained as `source.sed`. However, it is more useful to compute per-band fluxes, which integrate over the morphology. The convention of these fluxes is given by the units and ordering of the original data cube. In the case of multi-component sources, the fluxes of all components are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"----------------- {}\".format(filters))\n",
    "for k, src in enumerate(sources):\n",
    "    print (\"Source {}, Fluxes: {}\".format(k, scarlet.measure.flux(src)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other measurements (e.g. `centroid`) are also implemented. The measurement approach is also easily extendable. The source models are generated in the model frame (which is the best-fit representation of the full hyperspectral `Frame`), from which any measurement can directly be made without having to deal with noise, PSF convolution, overlapping sources, etc. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

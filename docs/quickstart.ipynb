{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n",
    "This tutorial shows how to quickly get started using *scarlet* to model an hyperspectral image cube. For a more in-depth introduction to *scarlet*, read our [User Guide](user_docs.ipynb).\n",
    "\n",
    "In order to run this tutorial you will need either `astropy` (http://www.astropy.org) or `sep` (https://github.com/kbarbary/sep) installed to open/create the source catalog and `matplotlib` (https://matplotlib.org) to display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import logging\n",
    "logger = logging.getLogger('scarlet')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(\"proxmin\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "import autograd.numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and display the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = np.load(\"../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "catalog = data[\"catalog\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.PSF(data[\"psfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a raw image cube\n",
    "This is an example of how to display an RGB image from an image cube of multiband data. In this case the image uses a $sinh^{-1}$ function to normalize the flux in each filter consistently to create an RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping\n",
    "\n",
    "stretch = 0.1\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model frame and the observation\n",
    "\n",
    "A `Frame` in *scarlet* is a description of the hyperspectral cube of the model or the observations. Think of it as the metadata, what aspects of the sky are described here. For observations, most of those are contained in FITS headers. At the least, a `Frame` holds the `shape` of the cube, for which we use the convention `(C, Ny, Nx)` for the number of elements in 3 dimensions: `C` for the number of bands/channels and `Ny, Nx` for the number of pixels at every channel.\n",
    "\n",
    "Additionally, you can and often must provide weights for all elements in the data cube, an image cube of the PSF model (one image for all or one for each channel), an `astropy.WCS` structure to translate from pixel to sky coordinates, and labels for all channels. The reason for specifying them is to enable the code to internally map from the model frame, in which you seek to fit a model, to the observed data frame.\n",
    "\n",
    "In this example, we assume that bands and pixel locations are identical between the model and the observation. But we have ground-based images with different PSFs in each band, so we need to provide a reference PSF for the model. We simply choose a minimal Gaussian PSF that is barely well sampled and use it as our reference kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and the `Observation`. Think of the latter as a `Frame` with a data portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = scarlet.Frame(images.shape, psf=model_psf, channels=filters)\n",
    "observation = scarlet.Observation(images, psf=psfs, weights=weights, channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous command calls the `match` method to compute e.g. PSF difference kernel and filter transformations.\n",
    "\n",
    "## Initialize the sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we call `Blend` is a collection of those sources.\n",
    "\n",
    "Each source is derived from `scarlet.Component` or from `scarlet.ComponentTree` in case of a multi-component source. We provide several pre-built source types:\n",
    "\n",
    "* `scarlet.PointSource` fits centers and per-band amplitude using the observed PSF model.\n",
    "* `scarlet.ExtendedSource` fits per-band amplitude and a non-parametric morphology (which can be constrained to be symmetric and/or monotonic with respect to the center).\n",
    "* `scarlet.MultiComponentSource` splits an `ExtendedSource` into multiple components that are initially radially separated.\n",
    "\n",
    "In our example, we assume *prior* knowledge that object 0 is a star, and object 1 should be modeled as a bulge-disc model. Everything else is assumed a galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 0:\n",
    "        new_source = scarlet.PointSource(model_frame, (src['y'], src['x']), observation)\n",
    "    elif k == 1:\n",
    "        new_source = scarlet.MultiComponentSource(model_frame, (src['y'], src['x']), observation, symmetric=False, monotonic=True, thresh=5)\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(model_frame, (src['y'], src['x']), observation, symmetric=False, monotonic=True, thresh=5)\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Note in the code above that coordinates in *scarlet* are set in the C/numpy notation (y,x) as opposed to the more conventional mathematical (x,y) ordering. Please use (y,x)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the model\n",
    "The `scarlet.Blend` class represent the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(blend.loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the full model\n",
    "First we load the model for the entire blend, render it in the observation frame, and compute its residuals. We then show model and date with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)\n",
    "residual = images-model_\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,component in enumerate(blend):\n",
    "    y,x = component.center\n",
    "    ax[0].text(x, y, k, color=\"w\")\n",
    "    ax[1].text(x, y, k, color=\"w\")\n",
    "    ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the source models\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame. In this example, the two frames differ by an extra convolution from the minimal `model_psf` to the observed psfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stretch based on the model\n",
    "stretch = .3\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "\n",
    "for k,src in enumerate(sources):\n",
    "    # Get the model for a single source\n",
    "    model = src.get_model()\n",
    "    model_ = observation.render(model)\n",
    "    \n",
    "    # Convert observation and models to RGB\n",
    "    img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "    model_rgb = scarlet.display.img_to_rgb(model, norm=norm)\n",
    "    model_rgb_ = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "\n",
    "    # Set the figure size\n",
    "    ratio = src.frame.shape[2]/src.frame.shape[1]\n",
    "    fig_height = 3*src.frame.shape[1]/20\n",
    "    fig_width = max(2*fig_height*ratio,2)\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Generate and show the figure\n",
    "    ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[0].set_title(\"Data\")\n",
    "    ax[1].imshow(model_rgb_)\n",
    "    ax[1].set_title(\"Observed model {0}\".format(k))\n",
    "    ax[2].imshow(model_rgb)\n",
    "    ax[2].set_title(\"Model {0}\".format(k))\n",
    "    # Mark the source in the data image\n",
    "    y,x = src.center\n",
    "    ax[0].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    ax[1].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    ax[2].plot(x, y, \"wx\", mew=1, ms=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model of object 0 assumes a simple Gaussian shape, which is the internal representation of a point source. It also shows the effective PSF of all the other models. Source 1 uses the freedom of the 2-compoent model to represent a slightly redder core.\n",
    "\n",
    "### SEDs and Fluxes\n",
    "\n",
    "We can further get the per-band fluxes of all objects. The convention of these fluxes is given by the units and ordering of the original data cube. In the case of multi-component sources, the fluxes are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, src in enumerate(sources):\n",
    "    print (\"Source {}, Fluxes: {}\".format(k, src.get_flux()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and Errors\n",
    "\n",
    "Internally, `Blend` solves an optimization problem, namely reducing the loss by adjusting the parameters of each component. The loss is the log-likelihood of the observed data given the model. Every component can declare its own parameters, which we can access by with the `parameters` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,src in enumerate(sources):\n",
    "    for p in src.parameters:\n",
    "        print (\"Source {}, Parameter shape {}, Converged {}\".format(k, p.shape, p.converged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter with length 5 is the SED, while the other describes the morphology. For object 0, this is simple a 2D center, the rest use images of different sizes.\n",
    "\n",
    "Each parameter is a souped up numpy array. It has attributes that store any constraints that were enforced during optimization, whether this parameter is considered converged, and an error estimate. In our example, several parameters have converged within relative changes of `e_rel=1e-3` (the default setting of `Blend.fit`), but others have not. This is why the fitter complained about non-convergence. The run above stopped because the loss did not change noticeably anymore.\n",
    "\n",
    "To demonstrate the use of error estimate, we make a signal-to-noise map of the morphology of source 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sources[5].parameters[1]\n",
    "plt.imshow(p / p.std)\n",
    "plt.colorbar(label='SNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNR map shows that the center region is well determined by the data. However, this error estimate is purely statistical and does not include correlations between different parameters or different components. In fact, there's an upper lobe in the top-left corner of this source that is part of source 0. The gradient optimizer would exploit that and increase the morphology values there, but the monotonicity constraint has largely prevented that."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

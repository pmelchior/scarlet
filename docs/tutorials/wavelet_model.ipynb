{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starlet Tutorial: Modeling a Low Surface Brightness Galaxy\n",
    "\n",
    "This tutorial goes through a case where the default `ExtendedSource` models will struggle: a complex low surface brightness galaxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word on starlets\n",
    "\n",
    "Starlets have the flexibility to represent any pixelated 2-D profile. We take advantage of this property and use starlets to model sources with features that are too complex to be modeled with only assumptions of symmetry or monotonicity, such as irregular galaxies and spiral galaxies.\n",
    "\n",
    "But first, the usual incantation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import astropy.io.fits as fits\n",
    "import sep \n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a superior colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none', origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load the data set (an image cube with 5 bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = pickle.load(open(\"../../data/lsbg.pkl\", \"rb\"))\n",
    "images = data[\"images\"]\n",
    "filters = data[\"channels\"]\n",
    "psf = data[\"psfs\"]\n",
    "\n",
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 1\n",
    "Q = 5\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Frame and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psf = scarlet.GaussianPSF(sigma = 0.8)\n",
    "\n",
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psf=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psf=scarlet.ImagePSF(psf),\n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Catalog\n",
    "\n",
    "Because we don't have a detection catalog, we need to build one. To avoid issues with merging peaks from different scales and false peaks at the lowest scale, we use the second scale for detection. We could use `detect = scarlet.detect.get_detect_wavelets(images, variance=0.1, scales=3)` to build a single band detection image, but we expand that method here to illustrate how to use starlet transforms in scarlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detection image by summing the images in all bands\n",
    "# (a more rigorous approach would be to create a chi^2 coadd).\n",
    "detect_image = np.sum(images, axis=0)\n",
    "# Define a rough standard deviation for the image.\n",
    "# This does not have to be exact, as it is fit by the\n",
    "# get_multiresolution_support algorithm below.\n",
    "sigma = 0.1\n",
    "# Find the wavelet coefficients\n",
    "coeffs = scarlet.wavelet.starlet_transform(detect_image, scales=3)\n",
    "# Determine the significant coefficients\n",
    "# (as defined in Starck et. al 2011)\n",
    "M = scarlet.wavelet.get_multiresolution_support(detect_image, coeffs, sigma, K=3, epsilon=1e-1, max_iter=20)\n",
    "# Use the multi-resolution support to select only\n",
    "# the relevant pixels for detection\n",
    "detect = M * coeffs\n",
    "# We are only detecting positive peaks, so there\n",
    "# is no need to include the negative coefficients\n",
    "detect[detect<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created two different sets of wavelet coefficents above. The first is the set of wavelet coeffiecients in the first three scales (and the residual image with lower frequency flux) and second is only those coefficients that are determined to be \"significant\" according to the algorithm in Starck et al. 2011.\n",
    "\n",
    "Below we view both sets of coefficents, and compare the reconstruction of the full set of wavelet coefficients with the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the detection coefficients\n",
    "lvl = detect.shape[0]\n",
    "plt.figure(figsize = (lvl*5+5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    img = detect[i]\n",
    "    img = np.arcsinh(10*img)/10\n",
    "    vmax = np.max(np.abs(img))\n",
    "    plt.imshow(img, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Display the detection coefficients\n",
    "lvl = detect.shape[0]\n",
    "plt.figure(figsize = (lvl*5+5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    img = coeffs[i]\n",
    "    img = np.arcsinh(10*img)/10\n",
    "    vmax = np.max(np.abs(img))\n",
    "    plt.imshow(img, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "reconstruction = scarlet.wavelet.starlet_reconstruction(coeffs)\n",
    "residual = detect_image - reconstruction\n",
    "\n",
    "#Making sure we recover the original image:\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original image', fontsize = 20)\n",
    "vmax = np.max(np.abs(detect_image))\n",
    "plt.imshow(detect_image, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.title('Starlet-reconstructed image', fontsize = 20)\n",
    "vmax = np.max(np.abs(reconstruction))\n",
    "plt.imshow(reconstruction, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.title('Data - Reconstruction', fontsize = 20)\n",
    "vmax = np.max(np.abs(residual))\n",
    "plt.imshow(residual, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect footprints and peaks on the 2nd scale in the `detect` image defined above. Notice that most footprints have a single peak, while a few footprints, like the central region (peaks 15-18), have multiple peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet.detect_pybind11 import get_footprints\n",
    "\n",
    "# Calculate isolated footprints and their maxima\n",
    "# in the 2nd wavelet scale.\n",
    "footprints = get_footprints(detect[1], min_separation=0, min_area=10, thresh=0)\n",
    "\n",
    "# Display all of the footprints\n",
    "footprint_img = np.zeros(detect.shape[1:])\n",
    "peaks = []\n",
    "for fp in footprints:\n",
    "    bbox = scarlet.detect.bounds_to_bbox(fp.bounds)\n",
    "    footprint_img[bbox.slices] = fp.footprint\n",
    "    peaks += list(fp.peaks)\n",
    "\n",
    "# Now display the peaks on the original image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.contour(footprint_img, [0.5,], colors='w', linewidths=0.5)\n",
    "for k, peak in enumerate(peaks):\n",
    "    plt.text(peak.x, peak.y, str(k), color=\"w\", ha='center', va='center', size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Starlet Components\n",
    "\n",
    "The extended diffuse emission wasn't detected as level 2 as a distinct single peak. Instead, we have a collection of many peaks, some of which are likely part of the LSB, but it's hard to tell from a visual inspection.\n",
    "\n",
    "We'll model every detected peak as `ExtendedSource` and add a `StarletSource` to pick up the diffuse emission. In a second step below, we'll merge source that have very similar color to the diffuse light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [(peak.y, peak.x) for peak in peaks]\n",
    "sources, skipped = scarlet.initialization.init_all_sources(model_frame,\n",
    "                                                           centers,\n",
    "                                                           observation,\n",
    "                                                           max_components=1,\n",
    "                                                           min_snr=50,\n",
    "                                                           thresh=1,\n",
    "                                                           fallback=True,\n",
    "                                                           silent=True,\n",
    "                                                           set_spectra=False\n",
    "                                                          )\n",
    "# Use a random seed to get consistent models in this demo\n",
    "np.random.seed(0)\n",
    "\n",
    "sources.append(scarlet.source.StarletSource(model_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time it, logL = blend.fit(200, e_rel=1e-6)\n",
    "print(f\"scarlet ran for {it} iterations to logL = {logL}\")\n",
    "scarlet.display.show_likelihood(blend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We use `scarlet.display.show_scene` to render the entire scene. It shows model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True,\n",
    "                          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                             add_boxes=True\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtracting the LSBG components\n",
    "\n",
    "Inspecting the source models above we see that the `StarletSource` indeed picked up a lot of the diffuse emission, but that several other sources have very similar spectrum to the LSB. We'll find them and combine their models to form what we think is the entire LSB galaxy, peaks as well as diffuse emission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all sources with very similar colors to the Starlet source of the diffuse emission\n",
    "spectrum = sources[-1].parameters[0]\n",
    "C = np.zeros(len(sources))\n",
    "for j, src in enumerate(sources):\n",
    "    spectrum_ = src.parameters[0]\n",
    "    # cosine similarity\n",
    "    C[j] = spectrum @ spectrum_ / np.sqrt(spectrum @ spectrum) / np.sqrt(spectrum_ @ spectrum_)\n",
    "\n",
    "lsbg = sum( sources[j].get_model(frame=model_frame) for j in range(len(sources)) if C[j] > 0.995)\n",
    "model = blend.get_model() - lsbg\n",
    "lsbg = observation.render(lsbg)\n",
    "\n",
    "res_rgb = scarlet.display.img_to_rgb(images-lsbg, norm=norm)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "lsbg_rgb = scarlet.display.img_to_rgb(lsbg, norm=norm)\n",
    "model_rgb = scarlet.display.img_to_rgb(images-model, norm=norm)\n",
    "\n",
    "plt.figure(figsize = (30,15))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(res_rgb)\n",
    "plt.title(\"Image - LSB\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(lsbg_rgb)\n",
    "plt.title(\"LSB\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet toy-model\n",
    "\n",
    "This tutorial shows how to use the the WaveletSource instead of pixelated sources. For a more in-depth introduction to *scarlet*, read the [Core Concepts](1-concepts.ipynb) or the [API Documentation](api/index.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a superior colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gist_stern', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We load an example data set (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available packages like [SEP](http://sep.readthedocs.io/) and [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one, but for this example we use part of the detection catalog generated by the [LSST DM stack](https://github.com/lsst). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the sample images\n",
    "data = np.load(\"../../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "catalog = data[\"catalog\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.PSF(data[\"psfs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how the wavelet transform and inverse transform works in scarlet. As a check we make sure that the transform and its inverse lead to the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare a starlet object (and performs the transform)\n",
    "Sw = scarlet.Starlet(images, lvl = 4, direct = True)\n",
    "#This is the starlet transform as an array\n",
    "w = Sw.coefficients\n",
    "#The inverse starlet transform of w (new object otherwise, the tranform is not used)\n",
    "iw = Sw.image\n",
    "\n",
    "#The wavelet transform of the first slice of images in pictures:\n",
    "lvl = w.shape[1]\n",
    "plt.figure(figsize = (lvl*5,5))\n",
    "plt.suptitle('Wavelet coefficients')\n",
    "for i in range(lvl):\n",
    "    plt.subplot(1,lvl,i+1)\n",
    "    plt.title('scale'+str(i+1))\n",
    "    plt.imshow(w[0,i])\n",
    "    plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Making sure we recover the original image:\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(131)\n",
    "plt.title('Original image', fontsize = 20)\n",
    "plt.imshow(images[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.title('Starlet-reconstructed image', fontsize = 20)\n",
    "plt.imshow(iw[0])\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.title('Absolute difference', fontsize = 20)\n",
    "plt.imshow((np.abs(iw[0]-images[0])))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Image Cube\n",
    "This is an example of how to display an RGB image from an image cube of multiband data. In this case the image uses a $sinh^{-1}$ function to normalize the flux in each filter consistently to create an RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "stretch = 0.2\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "# Mark all of the sources from the detection cataog\n",
    "for k, src in enumerate(catalog):\n",
    "    plt.text(src[\"x\"], src[\"y\"], str(k), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Frame and Observation\n",
    "\n",
    "A `Frame` in *scarlet* is a description of the hyperspectral cube of the model or the observations. Think of it as the metadata, what aspects of the sky are described here. At the least, a `Frame` holds the `shape` of the cube, for which we use the convention `(C, Ny, Nx)` for the number of elements in 3 dimensions: `C` for the number of bands/channels and `Ny, Nx` for the number of pixels at every channel.\n",
    "\n",
    "An `Observation` combines a `Frame` with several data units, similar to header-data arrangement in FITS files. In addition to the actual science image cube, you can and often must provide weights for all elements in the data cube, an image cube of the PSF model (one image for all or one for each channel), an `astropy.WCS` structure to translate from pixel to sky coordinates, and labels for all channels. The reason for specifying them is to enable the code to internally map from the model frame, in which you seek to fit a model, to the observed data frame."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It is crictical to realize that there are two frames: one for model that reconstructs the scene on the sky, and one for any observation of the scene. They may be identical, but mostly they are not, in which case the observation is an information-reduced rendering of the model. The loss of information could be in terms of signal-to-noise ratio, spatial resolution, PSF blurring, spectral coverage, or all of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we assume that bands and pixel locations are identical between the model and the observation. Because we have ground-based images with different PSFs in each band, we need to provide a reference PSF for the model. We simply choose a minimal Gaussian PSF that is barely well sampled as our reference kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = scarlet.Frame(\n",
    "    images.shape,\n",
    "    psfs=model_psf,\n",
    "    channels=filters)\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psfs=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last command calls the `match` method to compute e.g. PSF difference kernel and filter transformations.\n",
    "\n",
    "We generally recommend this pattern:\n",
    "1. define model frame\n",
    "2. construct observation\n",
    "3. match it to the model frame\n",
    "\n",
    "Steps 2 and 3 are combined above using a fluent pattern.\n",
    "\n",
    "## Initialize sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we will call `Blend`, is a collection of those sources. We provide several pre-built source types:\n",
    "\n",
    "* `PointSource` fits centers and per-band amplitude using the observed PSF model.\n",
    "* `WaveletSource` fits per-band amplitude and a non-parametric morphology in wavelet space and constrained in its L0 norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = scarlet.mad_wavelet(images)\n",
    "\n",
    "sources = []\n",
    "for k,src in enumerate(catalog):\n",
    "    if k == 0:\n",
    "        new_source = scarlet.PointSource(model_frame, (src['y'], src['x']), observation)\n",
    "    else:\n",
    "        new_source = scarlet.StarletSource(model_frame, (src['y'], src['x']), observation)\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Coordinates in *scarlet* are given in the C/numpy notation (y,x) as opposed to the more conventional mathematical (x,y) ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit Model\n",
    "The `Blend` class represents the sources as a tree and has the machinery to fit all of the sources to the given images. In this example the code is set to run for a maximum of 200 iterations, but will end early if the likelihood and all of the constraints converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "%time blend.fit(200, e_rel = 1.e-6)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Scene\n",
    "\n",
    "We could use `scarlet.display.show_scene` to render to entire scene, but it's instructive to see how the model and the comparison to observations is performed.\n",
    "First we load the model for the entire scene, render it in the observation frame, and compute its residuals. We then show model and data with the same $sinh^{-1}$ stretch and the residuals with a linear stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)\n",
    "residual = images-model_\n",
    "\n",
    "# Create RGB images\n",
    "model_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "residual_rgb = scarlet.display.img_to_rgb(residual)\n",
    "\n",
    "# Show the data, model, and residual\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "ax[1].imshow(model_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "ax[2].imshow(residual_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "for k,component in enumerate(blend):\n",
    "    y,x = component.center\n",
    "    ax[0].text(x, y, k, color=\"w\")\n",
    "    ax[1].text(x, y, k, color=\"w\")\n",
    "    ax[2].text(x, y, k, color=\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "\n",
    "We will now inspect the model for each source, in its original frame and in its observed frame by leveraging the `show_sources` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, \n",
    "                             norm=norm, \n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

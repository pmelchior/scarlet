{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Scenes\n",
    "\n",
    "A key feature of *scarlet* is operating with hyperspectral descriptions of celestial scenes. Color perception is thus critical to assessing the quality of the models. \n",
    "[Lupton et al. 2004](https://iopscience.iop.org/article/10.1086/382245) showed a consistent way of mapping three broad-band images onto RGB channels for visualization. The key is to normalize the image intensity, not each band, to preserve the color from the bright to the faint regions. Otherwise, the centers of bright objects all appear as white. \n",
    "\n",
    "We will often use the `arcsinh` function to normalize the intensities for objects with a wide range of fluxes:\n",
    "\n",
    "$$f(x) = \\frac{1}{Q} \\sinh^{-1} \\left( Q \\frac{x-x_\\textrm{min}}{\\textrm{stretch}} \\right)$$\n",
    "\n",
    "where `Q` is the same as the $\\beta$ softening parameter from [Lupton et al. 2004](https://iopscience.iop.org/article/10.1086/382245) and `stretch` determines the size of the linear region. This mapping is implemented in the [LSST software stack](https://github.com/lsst/afw/blob/master/python/lsst/afw/display/rgb/rgbContinued.py#L282-L321) and also in [astropy.visualization.make_lupton_rgb](http://docs.astropy.org/en/stable/api/astropy.visualization.make_lupton_rgb.html#astropy.visualization.make_lupton_rgb).\n",
    "\n",
    "The first step is thus to adjust the parameters `Q` and `stretch` such that the image brings out the features you want to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a good colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno', interpolation='none')\n",
    "\n",
    "# Load the sample images\n",
    "data = np.load(\"../../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "catalog = data[\"catalog\"]\n",
    "filters = data[\"filters\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.PSF(data[\"psfs\"])\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psfs=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters)\n",
    "\n",
    "# Set the arcsinh color scaling object\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(9,12))\n",
    "for i, stretch in enumerate([0.01, 0.1, 1]):\n",
    "    for j, Q in enumerate([1, 10, 100]):\n",
    "        asinh = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "        # Scale the RGB channels for the image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images, norm=asinh)\n",
    "        ax[i][j].imshow(img_rgb)\n",
    "        ax[i][j].set_title(\"Stretch {}, Q {}\".format(stretch, Q))\n",
    "        ax[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values around `Q=10` and `stretch=0.1` look reasonable, so we will proceed with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm =  AsinhMapping(minimum=0, stretch=0.1, Q=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set the minimum value to 0, which renders all negative values as black. This is reasonable for background-subtracted images, but may not be the right choice in all situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Filter Weights\n",
    "\n",
    "*scarlet* adds the functionality of mapping images with *more* than three bands into RGB channels. The method `channels_to_rgb` we've implicitly used above takes a hyperspectral data cube or multiband image (with $C$ channels) as an input and converts it to RGB colors using the $3\\times C$ linear mapping `channel_map`, and then normalizes the intensity in RGB space with the chosen norm.\n",
    "\n",
    "Above, it used its default mapping (for 5 bands), which assumes the that bands are ordered from the shortest wavelength to the longest. We can have a look at the defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarlet.display\n",
    "print(\"Mapping from 1 band to RGB:\\n\", scarlet.display.channels_to_rgb(1))\n",
    "print(\"Mapping from 3 bands to RGB:\\n\", scarlet.display.channels_to_rgb(3))\n",
    "print(\"Mapping from 5 bands to RGB:\\n\", scarlet.display.channels_to_rgb(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the filter weights for a single band give equal weight to all three RGB channels, while the three-band case maps cleanly onto RGB channels. For more than three channels this mapping is not uniquely definable. This allows us to adjust the filter weights to e.g. visually isolate specific colors, reduce the impact of noise in a filter, or even mimic human perception.\n",
    "\n",
    "Here we will adjust the filter weights to reduce the noise from the reddest Y band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(9,12))\n",
    "\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title('Default')\n",
    "ax[0].axis('off');\n",
    "\n",
    "channel_map = scarlet.display.channels_to_rgb(5)\n",
    "channel_map[0, :] = [0, 0, 0.2, 0.5, 0.3]\n",
    "channel_map /= channel_map.sum(axis=1)[:,None]\n",
    "print(\"New channel map:\\n\", channel_map)\n",
    "\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm, channel_map=channel_map)\n",
    "ax[1].imshow(img_rgb)\n",
    "ax[1].set_title('Less Y')\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Model\n",
    "\n",
    "Often we want to visually inspect the *scarlet* models and compare them to the observations. We provide two convenience functions in the `scarlet.display` module.\n",
    "\n",
    "* `show_scene` combines all sources and renders the full scene\n",
    "* `show_source` presents every source or every source component individually.\n",
    "\n",
    "Let's demonstrate these methods with the model from the [Quick Start Tutorial](../0-quickstart.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fp = open(\"../hsc_cosmos_35.sca\", \"rb\")\n",
    "sources = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "model_frame = sources[0].model_frame\n",
    "observation = observation.match(model_frame)\n",
    "\n",
    "scarlet.display.show_scene(sources, norm=norm, channel_map=channel_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we include the `plt.show()` at the end of the cell above. This is because `show_scene` returns the matplotlib `figure`, which is useful in cases where you might want to add annotations onto your plots, however without showing the scene or closing the figure the Jupyter notebook will display the figure twice.\n",
    "\n",
    "The other thing that you'll notice is that in this case the model extends beyond the range of the observation. This is because some of the sources were initialized in a symmetrized box that extended beyond the observation. If we just want to view the region of the model inside the observed region we can pass a full blend, which only displays the cosntrained region by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = scarlet.Blend(sources, observation)\n",
    "scarlet.display.show_scene(blend, norm=norm, channel_map=channel_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare it to data, we need to provide the observation and make sure that the observed frame is matched to the model frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = sources[0].model_frame # any source carries the frame\n",
    "observation = observation.match(model_frame)\n",
    "\n",
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           channel_map=channel_map, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic goes for the individual sources, with the option of also showing the SED of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, norm=norm, channel_map=channel_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source 1 is modelled with 2 components, and the SED is shown for them separately. If we wanted to see the images of the components, we can just pass the source itself to `show_sources`. For good measure, we also switch on the rendering and the observation at the same location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources[1], \n",
    "                             norm=norm, \n",
    "                             channel_map=channel_map,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

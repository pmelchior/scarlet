{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Scenes\n",
    "\n",
    "A key feature of *scarlet* is operating with hyperspectral descriptions of celestial scenes. Color perception is thus critical to assessing the quality of the models. \n",
    "[Lupton et al. 2004](https://iopscience.iop.org/article/10.1086/382245) showed a consistent way of mapping three broad-band images onto RGB channels for visualization. The key is to normalize the image intensity, not each band, to preserve the color from the bright to the faint regions. Otherwise, the centers of bright objects all appear as white. \n",
    "\n",
    "We will often use the `arcsinh` function to normalize the intensities for objects with a wide range of fluxes:\n",
    "\n",
    "$$f(x) = \\frac{1}{Q} \\sinh^{-1} \\left( Q \\frac{x-x_\\textrm{min}}{\\textrm{stretch}} \\right)$$\n",
    "\n",
    "where `Q` is the same as the $\\beta$ softening parameter from [Lupton et al. 2004](https://iopscience.iop.org/article/10.1086/382245) and `stretch` determines the size of the linear region. This mapping is implemented in the [LSST software stack](https://github.com/lsst/afw/blob/master/python/lsst/afw/display/rgb/rgbContinued.py#L282-L321) and also in [astropy.visualization.make_lupton_rgb](http://docs.astropy.org/en/stable/api/astropy.visualization.make_lupton_rgb.html#astropy.visualization.make_lupton_rgb).\n",
    "\n",
    "The first step is thus to find a define that brings out the features you want to show by adjusting the parameters `Q` and `stretch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "\n",
    "# Load the sample images\n",
    "data = np.load(\"../../data/hsc_cosmos_35.npz\")\n",
    "images = data[\"images\"]\n",
    "catalog = data[\"catalog\"]\n",
    "filters = data[\"filters\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "psfs = scarlet.PSF(data[\"psfs\"])\n",
    "\n",
    "observation = scarlet.Observation(\n",
    "    images, \n",
    "    psf=psfs, \n",
    "    weights=weights, \n",
    "    channels=filters)\n",
    "\n",
    "# Set the arcsinh color scaling object\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize=(9,12))\n",
    "for i, stretch in enumerate([0.01, 0.1, 1]):\n",
    "    for j, Q in enumerate([1, 10, 100]):\n",
    "        asinh = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "        # Scale the RGB channels for the image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images, norm=asinh)\n",
    "        ax[i][j].imshow(img_rgb)\n",
    "        ax[i][j].set_title(\"Stretch {}, Q {}\".format(stretch, Q))\n",
    "        ax[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values around `Q=10` and `stretch=0.1` look reasonable, so we will proceed with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm =  AsinhMapping(minimum=0, stretch=0.1, Q=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set the minimum value to 0, which renders all negative values as black. This is reasonable for background-subtracted images, but may not be the right choice in all situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Filter Weights\n",
    "\n",
    "*scarlet* adds the functionality of mapping images with *more* than three bands into RGB channels. The `img_to_channels` method we've already used above takes a hyperspectral data cube or multiband image (with $C$ channels) as an input and converts it to RGB colors using the $3\\times C$ linear mapping `filter_weights`, and then normalizes the intensity in RGB space with the chosen norm.\n",
    "\n",
    "Above it used its default mapping (for 5 bands), which assumes the that bands are ordered from the shortest wavelength to the longest. We can have a look at the defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarlet.display\n",
    "print(\"Mapping from 1 band to RGB:\\n\", scarlet.display.get_default_filter_weight(1))\n",
    "print(\"Mapping from 3 bands to RGB:\\n\", scarlet.display.get_default_filter_weight(3))\n",
    "print(\"Mapping from 5 bands to RGB:\\n\", scarlet.display.get_default_filter_weight(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the filter weights for a single band give equal weight to all three RGB channels, while the three-band case maps cleanly onto RGB channels. For more than three channels this mapping is not uniquely definable. This allows to adjust the filter weights to e.g. visually isolate specific colors, reduce the impact of noise in a filter, or even mimic human perception.\n",
    "\n",
    "Here we will adjust the filter weights to reduce the noise from the reddest Y band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(9,12))\n",
    "\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title('Default')\n",
    "ax[0].axis('off');\n",
    "\n",
    "filter_weights = scarlet.display.get_default_filter_weight(5)\n",
    "filter_weights[0, :] = [0, 0, 0.2, 0.5, 0.3]\n",
    "filter_weights /= filter_weights.sum(axis=1)[:,None]\n",
    "print(\"New filter weights:\\n\", filter_weights)\n",
    "\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm, filter_weights=filter_weights)\n",
    "ax[1].imshow(img_rgb)\n",
    "ax[1].set_title('Less Y')\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Model\n",
    "\n",
    "Often we want to visually inspect the *scarlet* models and compare them to the observations. We provide two convenience functions in the `scarlet.display` module.\n",
    "\n",
    "* `show_scene` combines all sources and renders to full scene\n",
    "* `show_source` presents every source or every source component individually.\n",
    "\n",
    "Let's demonstrate these methods with the model from the [Quick Start Tutorial](../quickstart.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fp = open(\"../hsc_cosmos_35.sca\", \"rb\")\n",
    "sources = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "model_frame = sources[0].frame\n",
    "observation = observation.match(model_frame)\n",
    "\n",
    "scarlet.display.show_scene(sources, norm=norm, filter_weights=filter_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare it to data, we need to provide the observation and make sure that the observed frame is matched to the model frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = sources[0].frame # any source carries the frame\n",
    "observation = observation.match(model_frame)\n",
    "\n",
    "scarlet.display.show_scene(sources, \n",
    "                           norm=norm, \n",
    "                           filter_weights=filter_weights, \n",
    "                           observation=observation, \n",
    "                           show_rendered=True, \n",
    "                           show_observed=True, \n",
    "                           show_residual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same logic goes for the individual sources, with the option of also showing the SED of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, norm=norm, filter_weights=filter_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source 1 is modelled with 2 components, and the SED is shown for them separately. If we wanted to see the images of the components, we can just pass the source itself to `show_sources`. For good measure, we also switch on the rendering and the observation at the same location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources[1], \n",
    "                             norm=norm, \n",
    "                             filter_weights=filter_weights,\n",
    "                             observation=observation,\n",
    "                             show_rendered=True, \n",
    "                             show_observed=True,\n",
    "                            )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

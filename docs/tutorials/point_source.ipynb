{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Source Tutorial\n",
    "\n",
    "This is a quick demonstration of how to model both extended objects and point sources in the same scence. After more testing we hope to replace this with a more robust demonstration of crowded field photometry, using an iterative detection/deblending procedure. In the meantime feel free to create your own algorithm for crowded fields and let us know how it goes on the [DESC Blending](https://lsstc.slack.com/messages/desc-blending) channel on slack.\n",
    "\n",
    "First we load a simulated image where we know the true value of all of the objects. This allows us to know which sources are galaxies and which ones are stars so we can use the appropriate source type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping, LinearMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to point to the location of the data on your system\n",
    "# Load the sample images\n",
    "data = np.load(\"../../data/psf_unmatched_sim.npz\")\n",
    "images = data[\"images\"]\n",
    "filters = data[\"filters\"]\n",
    "psfs = data[\"psfs\"]\n",
    "catalog = data[\"catalog\"]\n",
    "# Estimate of the background noise level\n",
    "bg_rms = np.array([20]*len(images))\n",
    "\n",
    "# display psfs\n",
    "pnorm = AsinhMapping(minimum=psfs.min(), stretch=psfs.max()/20, Q=20)\n",
    "prgb = scarlet.display.img_to_rgb(psfs, norm=pnorm)\n",
    "plt.imshow(prgb)\n",
    "plt.show()\n",
    "\n",
    "# Use Asinh scaling for the images\n",
    "norm = AsinhMapping(minimum=images.min(), stretch=10, Q=20)\n",
    "# Map i,r,g -> RGB\n",
    "# Convert the image to an RGB image\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the PSFs\n",
    "\n",
    "To avoid artifacts that arise when performing a full deconvolution on exteneded objects, we choose a small \"reference\" PSF and calculate the difference kernel to match the PSF in each band to that reference. See [Matching PSF's](psf_matching.ipynb) for a more detailed explanation of PSF matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target PSF to partially deconvolve the image psfs\n",
    "model_psf, _, _ = scarlet.psf.fit_target_psf(psfs, scarlet.psf.moffat)\n",
    "model_psf = model_psf[None,:,:]\n",
    "model_rgb = scarlet.display.img_to_rgb(model_psf, norm=pnorm)\n",
    "# Display the target PSF using the same scaling as the observed PSFs\n",
    "plt.imshow(model_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Frame and the Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = scarlet.Frame(images.shape, psfs=model_psf)\n",
    "observation = scarlet.Observation(images, psfs=psfs).match(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the sources\n",
    "\n",
    "Here is where we define the sources. In this case we know which ones are stars and which are galaxies, which may or may not be realistic depending on the depth and locations of the images taken. For example, at depths shallower than GAIA it should be possible to flag most of the stars in regions outside the galactic bulge, while in more crowded fields or long exposures a different method might be needed (such as color priors on stars vs galaxies) to determine which sources to model as point sources and which ones to model as extended objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initalize the sources\n",
    "sources = []\n",
    "for idx in np.unique(catalog[\"index\"]):\n",
    "    src = catalog[catalog[\"index\"]==idx][0]\n",
    "    if src[\"is_star\"]:\n",
    "        new_source = scarlet.PointSource(\n",
    "            frame, \n",
    "            (src[\"y\"], src[\"x\"]),\n",
    "            observation,\n",
    "            fix_morph=True, # This prevents the source morphology from changing\n",
    "        )\n",
    "    else:\n",
    "        new_source = scarlet.ExtendedSource(\n",
    "            frame,\n",
    "           (src[\"y\"], src[\"x\"]),\n",
    "            observation,\n",
    "            bg_rms=bg_rms,\n",
    "        )\n",
    "    sources.append(new_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we fix the morphology (`fix_morph=True`) and normalize the $S$ matrix for point sources. This allows us to only set the central pixel and never update it. This is described in more detail in the [User Guide](../user_docs.ipynb#Normalization). You'll also notice that we passed the point sources the full PSF in each band, whereas for the extended sources we pass the difference kernel. This is because a point source is a fully deconvolved representation of the object while extended sources are partially deconvolved. It also means that we have to be careful if we have a scene like this that is a mixture of extended sources and point sources. In order to have a consistent sparse (partially deconvolved) representation of the scene we need to convolve the point sources with the _target PSF_, not the full PSF that matches the image, once deblending has been completed to generate our model.\n",
    "\n",
    "Also notice that we used the same $S$ normalization for both the point sources and extended sources, which allows us to have a consistent definition of $A$ and $S$ for all sources, regardless of their type.\n",
    "\n",
    "## Create the blend and initialize the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Blend object, which later fits the model\n",
    "blend = scarlet.Blend(sources, observation)\n",
    "\n",
    "# Display the initial model\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)\n",
    "img_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "plt.imshow(img_rgb)\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        plt.plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our three stars (the red x's) are initialized to match their peak value with the peak of the image while the extended sources are initialized in the usual way.\n",
    "\n",
    "## Fit the model and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "blend.fit(200)\n",
    "print(\"Fit for {0} iterations\".format(blend.it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = [fig.add_subplot(1,3,n+1) for n in range(3)]\n",
    "\n",
    "# Display the data\n",
    "img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title(\"Data\")\n",
    "for src in catalog:\n",
    "    if src[\"is_star\"]:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"rx\", mew=2)\n",
    "    else:\n",
    "        ax[0].plot(src[\"x\"], src[\"y\"], \"bx\", mew=2)\n",
    "\n",
    "# Display the model\n",
    "model = blend.get_model()\n",
    "model_ = observation.render(model)\n",
    "img_rgb = scarlet.display.img_to_rgb(model_, norm=norm)\n",
    "ax[1].imshow(img_rgb)\n",
    "ax[1].set_title(\"Model\")\n",
    "for k, src in enumerate(blend.sources):\n",
    "    y,x = src.pixel_center\n",
    "    ax[1].text(x, y, str(k), color=\"r\")\n",
    "\n",
    "# Display the residual\n",
    "residual = images-model_\n",
    "img_rgb = scarlet.display.img_to_rgb(residual)\n",
    "ax[2].imshow(img_rgb)\n",
    "ax[2].set_title(\"Residual\")\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "# Show the morphologies\n",
    "for k, src in enumerate(blend.sources):\n",
    "    asinh = AsinhMapping(minimum=0, stretch=1/20, Q=10)\n",
    "    morph = scarlet.display.img_to_rgb(src.morph, norm=asinh)\n",
    "    plt.title(\"Source {0}: star={1}\".format(k, catalog[catalog[\"index\"]==k][0][\"is_star\"]))\n",
    "    plt.imshow(morph)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Total residual {0}\".format(np.sum(np.abs(residual))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dipoles we see at the center of the stellar sources is because the catalog offset the centers of all the sources by a random amount and by fixing the morphology we also cannot adjust the position, which also caused the code to require a greater number of iterations for convergence. A future version of *scarlet* will hopefully address this unfortunate side effect of fitting PSF stars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Resolution Modeling\n",
    "\n",
    "This tutorial shows how to model sources frome images observed with different telescopes. We will use a multiband observation with the Hyper-Sprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from scarlet.display import AsinhMapping\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gist_stern')\n",
    "matplotlib.rc('image', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Display Data\n",
    "\n",
    "We first load the HSC and HST images, swapping the byte order if necessary because a bug in astropy does not respect the local endianness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HSC image data\n",
    "obs_hdu = fits.open('../../data/test_resampling/Cut_HSC1.fits')\n",
    "data_hsc = obs_hdu[0].data.byteswap().newbyteorder()\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "channels_hsc = ['g','r','i','z','y']\n",
    "\n",
    "# Load the HSC PSF data\n",
    "psf_hsc = fits.open('../../data/test_resampling/PSF_HSC.fits')[0].data\n",
    "Np1, Np2 = psf_hsc[0].shape\n",
    "psf_hsc = scarlet.PSF(psf_hsc)\n",
    "\n",
    "# Load the HST image data\n",
    "hst_hdu = fits.open('../../data/test_resampling/Cut_HST1.fits')\n",
    "data_hst = hst_hdu[0].data\n",
    "wcs_hst = WCS(hst_hdu[0].header)\n",
    "channels_hst = ['F814W']\n",
    "\n",
    "# Load the HST PSF data\n",
    "psf_hst = fits.open('../../data/test_resampling/PSF_HST.fits')[0].data\n",
    "psf_hst = psf_hst[None,:,:]\n",
    "psf_hst = scarlet.PSF(psf_hst)\n",
    "\n",
    "# Scale the HST data\n",
    "n1,n2 = np.shape(data_hst)\n",
    "data_hst = data_hst.reshape(1, n1, n2).byteswap().newbyteorder()\n",
    "\n",
    "r, N1, N2 = data_hsc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to create a source catalog for the images. We'll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sep\n",
    "\n",
    "class Data():\n",
    "    #An object to have easier access to the data\n",
    "    def __init__(self, images, wcss, psfs, channels):\n",
    "        self.images = images\n",
    "        self.wcs = wcss\n",
    "        self.psfs = psfs.image\n",
    "        self.channels = channels\n",
    "\n",
    "def interpolate(data_lr, data_hr):\n",
    "    #Interpolate the low resolution image to high resolution using sinc interpolation\n",
    "    coord_lr0 = (np.arange(data_lr.images.shape[1]), np.arange(data_lr.images.shape[1]))\n",
    "    coord_hr = (np.arange(data_hr.images.shape[1]), np.arange(data_hr.images.shape[1]))\n",
    "    coord_lr = scarlet.resampling.convert_coordinates(coord_lr0, data_lr.wcs, data_hr.wcs)\n",
    "    \n",
    "    interp = []\n",
    "    for image in data_lr.images:\n",
    "        interp.append(scarlet.interpolation.sinc_interp(image[None, :,:], coord_hr, coord_lr, angle=None)[0].T)\n",
    "    return np.array(interp)\n",
    "        \n",
    "def makeCatalog(data_lr, data_hr, lvl = 3, wave = True):\n",
    "    # Create a catalog of detected source by running SEP on the wavelet transform \n",
    "    # of the sum of the high resolution images and the low resolution images interpolated to the high resolution grid\n",
    "    #Interpolate LR to HR\n",
    "    interp = interpolate(data_lr, data_hr)\n",
    "    # Normalisation \n",
    "    interp = interp/np.sum(interp, axis = (1,2))[:,None, None]\n",
    "    hr_images = data_hr.images/np.sum(data_hr.images, axis = (1,2))[:,None, None]\n",
    "    # Summation to create a detection image\n",
    "    detect_image = np.sum(interp, axis = 0) + np.sum(hr_images, axis = 0)\n",
    "    # Rescaling to HR image flux\n",
    "    detect_image *= np.sum(data_hr.images)\n",
    "    # Wavelet transform\n",
    "    wave_detect = scarlet.Starlet(detect_image, direct = False).coefficients[0]\n",
    "    \n",
    "    if wave:\n",
    "        # Creates detection from the first 3 wavelet levels\n",
    "        detect = wave_detect[:lvl,:,:].sum(axis = 0)\n",
    "    else:\n",
    "        detect = detect_image\n",
    "    # Runs SEP detection\n",
    "    bkg = sep.Background(detect)\n",
    "    catalog = sep.extract(detect, 3, err=bkg.globalrms)\n",
    "    bg_rms = []\n",
    "    for data in datas:\n",
    "        img = data.images\n",
    "        if np.size(img.shape) == 3:\n",
    "            bg_rms.append(np.array([sep.Background(band).globalrms for band in img]))\n",
    "        else:\n",
    "            bg_rms.append(sep.Background(img).globalrms)\n",
    "        \n",
    "    return catalog, np.array(bg_rms), detect_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "data_hr =  Data(data_hst, wcs_hst, psf_hst, channels_hst)\n",
    "data_lr =  Data(data_hsc, wcs_hsc, psf_hsc, channels_hsc)\n",
    "datas = [data_lr, data_hr]\n",
    "# Making catalog. \n",
    "# With the wavelet option on, only the first 3 wavelet levels are used for detection. Set to 1 for better detection\n",
    "wave = 1\n",
    "lvl = 3\n",
    "catalog_hst, bg_rms, detect = makeCatalog(data_lr, data_hr, lvl, wave)\n",
    "\n",
    "weights_hst = np.ones_like(data_hst) / (bg_rms[1]**2)[:, None, None]\n",
    "weights_hsc = np.ones_like(data_hsc) / (bg_rms[0]**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can visualize both the multiband HSC and single band HST images in their native resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color mapping for the HSC image\n",
    "hsc_norm = AsinhMapping(minimum=-1, stretch=2, Q=10)\n",
    "hst_norm = AsinhMapping(minimum=-1, stretch=10, Q=5)\n",
    "\n",
    "# Get the source coordinates from the HST catalog\n",
    "xo,yo = catalog_hst['x'], catalog_hst['y']\n",
    "# Convert the HST coordinates to the HSC WCS\n",
    "ra, dec = wcs_hst.wcs_pix2world(yo,xo,0)\n",
    "\n",
    "Yo,Xo, l = wcs_hsc.wcs_world2pix(ra, dec, 0, 0)\n",
    "# Map the HSC image to RGB\n",
    "img_rgb = scarlet.display.img_to_rgb(data_hsc, norm=hsc_norm)\n",
    "# Apply Asinh to the HST data\n",
    "hst_img = scarlet.display.img_to_rgb(data_hst, norm=hst_norm)\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_rgb)\n",
    "plt.plot(Xo,Yo, 'or')\n",
    "plt.subplot(122)\n",
    "plt.imshow(hst_img)\n",
    "plt.plot(xo,yo, 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "Unlike the single resolution examples, we now have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. Because there is no resampling between the model frame and the HST observation, we can use the default `Observation` class for the HST data. The HSC images have lower resolution, so we need to resample the models to this frame, and that's done by `LowResObservation`.\n",
    "\n",
    "Users can specify frame, Observation and LowResObservation objects by hand and match them as is usually done in single observation fitting. Alternativelly, the user can provide a list of observation (no matter what the resolution of each observation is), from which the `from_observations` method will decide which observation(s) should be a LowResObservations. If no psf or reference wcs is provided, the method will also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Automated frame definition\n",
    "# define two observation packages and match to frame\n",
    "obs_hst = scarlet.Observation(data_hst, wcs=wcs_hst, psfs=psf_hst, channels=channels_hst, weights=weights_hst)\n",
    "obs_hsc = scarlet.Observation(data_hsc, wcs=wcs_hsc, psfs=psf_hsc, channels=channels_hsc, weights=weights_hsc)\n",
    "\n",
    "# Keep the order of the observations consistent with the `channels` parameter\n",
    "# This implementation is a bit of a hack and will be refined in the future\n",
    "obs = [obs_hsc, obs_hst]\n",
    "frame = scarlet.Frame.from_observations(obs, coverage = 'intersection')\n",
    "obs_hsc, obs_hst = obs\n",
    "\n",
    "detect *= np.sum(data_hst)/np.sum(detect)\n",
    "#Using the detection images to initialise sources. This helps make a joint decision across observations \n",
    "# in particular regarding box sizes\n",
    "obs_detect = scarlet.Observation(detect[None,:,:], wcs=wcs_hst, psfs=psf_hst, channels=channels_hst)\n",
    "obs_detects = [obs_hsc, obs_detect]\n",
    "frame_detect = scarlet.Frame.from_observations(obs_detects, coverage = 'intersection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources and Blend\n",
    "\n",
    "We expect all sources to be galaxies, so we initialized them as `ExtendedSources`. Because the initialization takes a list of observations, we set the `obs_idx` argument to state which observation in the list of observations is used to initialize the morphology.\n",
    "\n",
    "`Blend` will hold a list of all sources and *all* observations to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better detections, turn obs into obs_detect in sources\n",
    "sources = [\n",
    "    scarlet.ExtendedSource(frame_detect, (ra[i], dec[i]), obs, \n",
    "                           symmetric=False, \n",
    "                           monotonic=True, \n",
    "                           obs_idx=1)\n",
    "    for i in range(ra.size)\n",
    "]\n",
    "\n",
    "blend = scarlet.Blend(sources, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Initial guess\n",
    "\n",
    "Let's compare the initial guess of the model in both model frame and HSC observation frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and calculate the residual\n",
    "model = blend.get_model()\n",
    "\n",
    "%time obs_hsc.render(model)\n",
    "model_lr = obs_hsc.render(model)\n",
    "init_rgb = scarlet.display.img_to_rgb(model[:-1], norm=hsc_norm)\n",
    "init_rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:-5])\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - obs_hst.render(model))[0]\n",
    "vmax = residual_hr.max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(231)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(init_rgb)\n",
    "plt.title(\"HighRes Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(init_rgb_lr)\n",
    "plt.title(\"LowRes Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time blend.fit(20, e_rel = 1.e-5)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Model\n",
    "First we load the model for the entire blend and its residual. Then we display the model using the same $sinh^{-1}$ stretch as the full image and a linear stretch for the residual to see the improvement from our initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = blend.get_model()\n",
    "model_hr = obs_hst.render(model)\n",
    "model_lr = obs_hsc.render(model)\n",
    "\n",
    "rgb = scarlet.display.img_to_rgb(model[:-1], norm=hsc_norm)\n",
    "rgb_lr = scarlet.display.img_to_rgb(model_lr, norm=hsc_norm)\n",
    "residual_lr = data_hsc - model_lr\n",
    "\n",
    "# Trim the bottom source not part of the blend from the image\n",
    "residual_lr_rgb = scarlet.display.img_to_rgb(residual_lr[:,:-5], norm=hsc_norm)\n",
    "\n",
    "# Get the HR residual\n",
    "residual_hr = (data_hst - model_hr)[0]\n",
    "vmax = residual_hr.max()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(231)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"HSC data\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"HST Model\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(rgb_lr)\n",
    "plt.title(\"HSC Model\")\n",
    "plt.subplot(236)\n",
    "plt.imshow(residual_hr, cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.colorbar(fraction=.045)\n",
    "plt.title(\"HST residual\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(residual_lr_rgb)\n",
    "plt.title(\"HSC residual\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(hst_img)\n",
    "plt.title('HST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Source Models\n",
    "It can also be useful to view the model for each source. For each source we extract the portion of the image contained in the sources bounding box, the true simulated source flux, and the model of the source, scaled so that all of the images have roughly the same pixel scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "has_truth = False\n",
    "axes = 2\n",
    "\n",
    "for k,src in enumerate(blend.sources):\n",
    "    print('source number ', k)\n",
    "    # Get the model for a single source\n",
    "    model = src.get_model()\n",
    "    model_lr = obs_hsc.render(model)\n",
    "    \n",
    "    # Display the low resolution image and residuals\n",
    "    img_lr_rgb = scarlet.display.img_to_rgb(model_lr, norm = hsc_norm)\n",
    "    res = data_hsc-model_lr\n",
    "    res_rgb = scarlet.display.img_to_rgb(res, norm = hsc_norm)\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    \n",
    "    plt.subplot(331)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.plot(Xo[k],Yo[k], 'x', markersize = 10)\n",
    "    plt.title(\"HSC Data\")\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(img_lr_rgb)\n",
    "    plt.title(\"LR Model\")\n",
    "    plt.subplot(333)\n",
    "    plt.imshow(res_rgb)\n",
    "    plt.title(\"LR Data - Model\")\n",
    "    \n",
    "    obs_slices, model_slices = scarlet.bbox.overlapped_slices(obs_hst.frame, src.bbox)\n",
    "    model = model[model_slices]\n",
    "    \n",
    "    img_hr = obs_hst.convolve(model)\n",
    "    _data_hst = data_hst[obs_slices]\n",
    "    res = _data_hst-img_hr[-1]\n",
    "    vmax = res.max()\n",
    "    \n",
    "    plt.subplot(334)\n",
    "    plt.imshow(_data_hst[-1], cmap='gist_stern', extent=scarlet.display.get_extent(src.bbox))\n",
    "    plt.plot(xo[k],yo[k], 'o', markersize = 5)\n",
    "    plt.title(\"HST Data\")\n",
    "    plt.subplot(335)\n",
    "    plt.imshow(img_hr[-1])\n",
    "    plt.title(\"HR Model\")\n",
    "    plt.subplot(336)\n",
    "    plt.imshow(res[0], cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    plt.title(\"HR Data - Model\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiscale deblending tutorial\n",
    "\n",
    "The idea behind deblending with wavelets is that in theory it should be easier to separate high frequency signals from low frequency signals, since sources are less blended a higher frequencies (the center of most astrophysical sources). In this tutorial two different types of wavelet deblending are attempted, as described below. But first we show the results using the current version of scarlet. This also serves as an example of how to implement your own deblending schemes using scarlet lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import logging\n",
    "logger = logging.getLogger('scarlet')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(\"proxmin\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "from scarlet.display import AsinhMapping, img_to_rgb\n",
    "from scarlet.operator import prox_monotonic_mask\n",
    "from scarlet.operators_pybind11 import get_valid_monotonic_pixels, linear_interpolate_invalid_pixels\n",
    "from scarlet.detect import get_detect_wavelets, get_blend_structures, bounds_to_bbox, get_peaks\n",
    "from scarlet.wavelet import (starlet_transform, get_multiresolution_support, starlet_reconstruction,\n",
    "                             multiband_starlet_transform, multiband_starlet_reconstruction)\n",
    "from scarlet.lite import LiteObservation, integrated_circular_gaussian, parameterize_sources, LiteBlend\n",
    "from scarlet.lite import init_adaprox_component, init_fista_component\n",
    "\n",
    "from astropy.table import Table as ApTable\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', interpolation='none', origin=\"lower\")\n",
    "prop_cycle = [c[\"color\"] for c in plt.rcParams['axes.prop_cycle']]\n",
    "\n",
    "\n",
    "def display_multiresolution_residuals(images, mask, blend, scales=3, stretch=0.2, Q=10, generation=1):\n",
    "    \"\"\"This function just displays the residual in each wavelet scale\n",
    "    \"\"\"\n",
    "    # Calculate the ratio of the height/width, used for layout\n",
    "    ratio = images.shape[-2] / images.shape[-1]\n",
    "    \n",
    "    # Load the unconvolved model\n",
    "    model = blend.get_model(convolve=False)\n",
    "    \n",
    "\n",
    "    # Display the original image and the model\n",
    "    norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 7.5*ratio))\n",
    "    rgb = scarlet.display.img_to_rgb(images, norm=norm, mask=mask)\n",
    "    ax[0].imshow(rgb)\n",
    "    ax[0].set_title(\"image\")\n",
    "    rgb = scarlet.display.img_to_rgb(blend.observation.convolve(model), norm=norm, mask=mask)\n",
    "    ax[1].imshow(rgb)\n",
    "    ax[1].set_title(\"convolved model\")\n",
    "    \n",
    "    for center in centers:\n",
    "        ax[0].plot(center[1], center[0], \"rx\")\n",
    "        ax[1].plot(center[1], center[0], \"rx\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the wavelet coefficients of the image and the model\n",
    "    w1 = multiband_starlet_transform(images, scales=scales, generation=generation)\n",
    "    w2 = multiband_starlet_transform(model, scales=scales, generation=generation)\n",
    "\n",
    "    # Convolve the wavelet coefficients in each band\n",
    "    c2 = w2.copy()\n",
    "    for s in range(scales+1):\n",
    "        c2[s] = observation.convolve(c2[s])\n",
    "\n",
    "    # Calculate the residual for all wavelet scales\n",
    "    residual = w1 - c2\n",
    "    # Display the image, model, and residual, at each wavelet scale\n",
    "    norm = AsinhMapping(minimum=np.min(images), stretch=stretch, Q=Q)\n",
    "    for s in range(scales + 1):\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20, 5*ratio))\n",
    "        rgb = scarlet.display.img_to_rgb(w2[s], norm=norm, mask=mask)\n",
    "        ax[0].imshow(rgb)\n",
    "        rgb = scarlet.display.img_to_rgb(w1[s], norm=norm, mask=mask)\n",
    "        ax[1].imshow(rgb)\n",
    "        rgb = scarlet.display.img_to_rgb(c2[s], norm=norm, mask=mask)\n",
    "        ax[2].imshow(rgb)\n",
    "        rgb = scarlet.display.img_to_rgb(residual[s], mask=mask)\n",
    "        ax[3].imshow(rgb)\n",
    "        for center in centers:\n",
    "            ax[3].plot(center[1], center[0], \"rx\")\n",
    "        for src in blend.sources:\n",
    "            if src.is_null:\n",
    "                continue\n",
    "            ax[3].plot(src.center[1], src.center[0], \"gx\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../../data/testdata_3_0.npz\")\n",
    "\n",
    "images = data[\"images\"]\n",
    "variance = data[\"variance\"]\n",
    "weights = 1/data[\"variance\"]\n",
    "mask = data[\"footprint\"]\n",
    "weights = weights * ~mask\n",
    "psfs = data[\"psfs\"]\n",
    "centers = data[\"centers\"]\n",
    "\n",
    "ratio = images.shape[-2] / images.shape[-1]\n",
    "\n",
    "# Use wavelet detection to detect more sources\n",
    "detect = get_detect_wavelets(images, variance, scales=5)\n",
    "centers = np.array(list(get_peaks(detect*~mask[None, :, :])))\n",
    "\n",
    "stretch = 0.2\n",
    "Q = 10\n",
    "norm = AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "rgb = scarlet.display.img_to_rgb(images, norm=norm, mask=mask)\n",
    "plt.imshow(rgb)\n",
    "for center in centers:\n",
    "    plt.plot(center[1], center[0], \"rx\")\n",
    "plt.title(\"image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla scarlet lite\n",
    "\n",
    "We first use the standard scarlet lite code to measure both the runtime and overall -logL (smaller is better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an internal model with a circular Gaussian PSF with sigma=0.8\n",
    "model_psf = integrated_circular_gaussian(sigma=0.8)\n",
    "# Create the observation class to hold the data\n",
    "observation = LiteObservation(images, variance, weights, psfs, model_psf[None, :, :])\n",
    "\n",
    "# Optimization using ADAM to update parameters\n",
    "adaprox_init = partial(init_adaprox_component, bg_thresh=0.25, max_prox_iter=1)\n",
    "# Optimization using FISTA (accelerated proximal gradient method) to update parameters\n",
    "fista_init = partial(init_fista_component, bg_thresh=0.25)\n",
    "# For this notebook we just use ADAM, since it gives the best results for all three algorithms for most blends\n",
    "parameterize = adaprox_init\n",
    "\n",
    "# Initialize the source morphologies and SEDs\n",
    "sources = scarlet.lite.init_all_sources_main(observation, centers)\n",
    "# Convert the components into sources that use the specified parameterization for optimization\n",
    "sources = parameterize_sources(sources, observation, parameterize)\n",
    "\n",
    "# Create the blend\n",
    "blend = LiteBlend(sources, observation)\n",
    "# Initialization by first using a joint fit for the SEDs\n",
    "blend.fit_spectra()\n",
    "# Fit all of the sources in the blend\n",
    "%time blend.fit(100, min_iter=100)\n",
    "print(f\"{blend.it} iterations to a final -logL of {-blend.loss[-1]:.0f}\")\n",
    "\n",
    "display_multiresolution_residuals(images, mask, blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using wavelets to calculate the loss function\n",
    "\n",
    "Using scarlet lite it is fairly straight-forward to update the loss function of the entire model so that instead of calculating the residuals of the model wrt the data in real space, it calculates the starlets (undecimated isotropic wavelets) for the model in each iteration, and compares the residuals of each wavelet scale separately. The idea was that this would be able to supress the high frequency spikes that are seen in the scarlet deconvolved models, but unfortunately it does not appear to work and gives _slightly_ worse results with slightly higher as vanialla scarlet with a higher runtime. ðŸ˜ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletBlend(LiteBlend):\n",
    "    \"\"\"A Blend that uses the wavelet coefficients to update the logL\n",
    "    \"\"\"\n",
    "    def grad_logL(self):\n",
    "        # Create the full model with all of the sources\n",
    "        model = self.get_model(convolve=True)\n",
    "        \n",
    "        # Calculate the wavelets in each band\n",
    "        wavelets = multiband_starlet_transform(model, self.observation.scales, observation.generation)\n",
    "        \n",
    "        # Update the loss (used for convergence check)\n",
    "        self.loss.append(0.5 * -np.sum(self.observation.weights * (self.observation.images - model)**2))\n",
    "        # Calculate the gradient wrt the model d(logL)/d(model)\n",
    "        grad_logL = self.observation.weights * (wavelets - self.observation.wavelets)\n",
    "        grad_logL = np.sum(grad_logL, axis=0)\n",
    "        grad_logL = self.observation.convolve(grad_logL, grad=True)\n",
    "        return grad_logL\n",
    "\n",
    "# Use 3 wavelet scales and a residual image\n",
    "scales = 3\n",
    "# Wavelet generation (gen 2 has an extra convolution that takes more time and gives worse results)\n",
    "generation = 1\n",
    "# Calculate the image wavelets and attach them to the observation\n",
    "wavelets = multiband_starlet_transform(images, scales=scales, generation=generation)\n",
    "observation.scales = scales\n",
    "observation.wavelets = wavelets\n",
    "observation.generation = generation\n",
    "\n",
    "# Initialize the source morphologies and SEDs\n",
    "sources = scarlet.lite.init_all_sources_main(observation, centers)\n",
    "# Convert the components into sources that use the specified parameterization for optimization\n",
    "sources = parameterize_sources(sources, observation, parameterize)\n",
    "\n",
    "# Create the blend\n",
    "blend = WaveletBlend(sources, observation)\n",
    "# Initialization by first using a joint fit for the SEDs\n",
    "blend.fit_spectra()\n",
    "# Fit all of the sources in the blend\n",
    "%time blend.fit(100, min_iter=100)\n",
    "print(f\"{blend.it} iterations to a final -logL of {-blend.loss[-1]:.0f}\")\n",
    "\n",
    "display_multiresolution_residuals(images, mask, blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use source models with wavelet coefficients\n",
    "\n",
    "The second test is to use a model for each source that contains wavelet coefficients, where the blend updates the coefficients at each scale with their residuals. The algorithm is similar to Starck et al. 2011 for calculating positive wavelet coefficients, the main difference being that we model each source (set of positive coefficients) separately, using the standard scarlet assumption that each component has a consistent color. However, in this case we allow that color to be different at each wavelet scale.\n",
    "\n",
    "Unfortunately the result is a worse fit, in more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scarlet.lite import LiteSource, init_monotonic_morph, LiteComponent, project_morph_to_center\n",
    "from scarlet.wavelet import bspline_convolve\n",
    "from scarlet.bbox import overlapped_slices, Box\n",
    "from scarlet.interpolation import get_filter_coords, get_filter_bounds\n",
    "\n",
    "\n",
    "class StarletConvolution:\n",
    "    \"\"\"Convolve a set of starlets with a bicubic spline at each scale\n",
    "    \n",
    "    In order to keep each component small and band limited to the\n",
    "    current scale we perform a separable convolution at each scale\n",
    "    with the appropriate bicubic spline filter. This class\n",
    "    keeps track of the filters needed at each scale and their\n",
    "    application to a set of wavelet coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, scales):\n",
    "        self.scales = scales\n",
    "        self.filters = {}\n",
    "\n",
    "        for scale in range(1, scales+1):\n",
    "            x1 = 2 ** scale\n",
    "            x2 = 2 ** (scale + 1)\n",
    "            x = np.linspace(-(x2 - 1), x2 - 1, 2 * x2 - 1)\n",
    "            y = (np.abs(x - x2) ** 3\n",
    "                 - 4 * np.abs(x - x1) ** 3\n",
    "                 +  6 * np.abs(x) ** 3\n",
    "                 - 4 * np.abs(x + x1) ** 3\n",
    "                 + np.abs(x + x2) ** 3) / 12\n",
    "            phi = y / np.sum(y)\n",
    "            phi_x = phi[None, :]\n",
    "            phi_y = phi_x.T\n",
    "            coords = get_filter_coords(phi_x)\n",
    "            bounds_x = get_filter_bounds(coords.reshape(-1, 2))\n",
    "            coords = get_filter_coords(phi_y)\n",
    "            bounds_y = get_filter_bounds(coords.reshape(-1, 2))\n",
    "            self.filters[scale] = ((phi_y.reshape(-1), phi_x.reshape(-1)), (bounds_y, bounds_x))\n",
    "    \n",
    "    def transform(self, wavelets, scale):\n",
    "        \"\"\"Transform the wavelet coefficients at a given scale\n",
    "        \"\"\"\n",
    "        from scarlet.operators_pybind11 import apply_filter\n",
    "\n",
    "        result = np.empty(wavelets.shape, dtype=wavelets.dtype)\n",
    "        phi, bounds = self.filters[scale]\n",
    "        # Convolve using the appropriate scale in the y-direction\n",
    "        apply_filter(\n",
    "            wavelets.copy(),\n",
    "            phi[0],\n",
    "            bounds[0][0],\n",
    "            bounds[0][1],\n",
    "            bounds[0][2],\n",
    "            bounds[0][3],\n",
    "            result,\n",
    "        )\n",
    "        # Convolve using the appropriate scale in the x-direction\n",
    "        apply_filter(\n",
    "            result.copy(),\n",
    "            phi[1],\n",
    "            bounds[1][0],\n",
    "            bounds[1][1],\n",
    "            bounds[1][2],\n",
    "            bounds[1][3],\n",
    "            result,\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def transform_single_band(self, wavelets):\n",
    "        \"\"\"Transform all of the wavelet coefficients for a single band\n",
    "        \"\"\"\n",
    "        result = wavelets.copy()\n",
    "        for scale in range(1, wavelets.shape[0]):\n",
    "            result[scale] = self.transform(wavelets[scale], scale)\n",
    "        return result\n",
    "    \n",
    "    def transform_multiband(self, wavelets):\n",
    "        \"\"\"Transform all of the wavelet coeffients, at all scales, in all bands\n",
    "        \"\"\"\n",
    "        result = wavelets.copy()\n",
    "        for scale in range(1, wavelets.shape[0]):\n",
    "            for b, w in enumerate(wavelets[scale]):\n",
    "                result[scale, b] = self.transform(w, scale)\n",
    "        return result\n",
    "\n",
    "\n",
    "class WaveletSource(LiteSource):\n",
    "    \"\"\"A source modeled as a set of wavelet coeffients\n",
    "    \n",
    "    Each component of the source is a set of wavelet\n",
    "    coefficients, where each component can have its\n",
    "    own SED (so the SED is allowed to vary by scale).\n",
    "    \"\"\"\n",
    "    def __init__(self, components, dtype, convolution):\n",
    "        self.components = components\n",
    "        self.dtype = dtype\n",
    "        self._flux = None\n",
    "        self.flux_bbox = None\n",
    "        self.convolution = convolution\n",
    "    \n",
    "    @property\n",
    "    def scales(self):\n",
    "        \"\"\"The number of wavelet scales\n",
    "        \"\"\"\n",
    "        return len(self.components) - 1\n",
    "\n",
    "    def get_model(self, bbox=None, use_flux=False, stacked=False, transform=True, observation=None):\n",
    "        \"\"\"Build the model for the source\n",
    "        \"\"\"\n",
    "        # Use the regular `LiteBlend` where appropriate\n",
    "        if self.n_components == 0 or use_flux:\n",
    "            return super().get_model(bbox, use_flux)\n",
    "\n",
    "        if bbox is None:\n",
    "            bbox = self.bbox\n",
    "        model = np.zeros((self.scales+1,) + bbox.shape, dtype=self.dtype)\n",
    "        for n, component in enumerate(self.components):\n",
    "            _model = component.get_model()\n",
    "            slices = overlapped_slices(bbox, component.bbox)\n",
    "            model[(n,)+slices[0]] += _model[slices[1]]\n",
    "        \n",
    "        if transform:\n",
    "            model = self.convolution.transform_multiband(model)\n",
    "        \n",
    "        if not stacked:\n",
    "            return np.sum(model, axis=0)\n",
    "        \n",
    "        if observation is not None:\n",
    "            assert not stacked\n",
    "            model = observation.convolve(model)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def update(self, it, grad_logL):\n",
    "        for scale, component in enumerate(self.components):\n",
    "            component.update(it, grad_logL[scale])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"WaveletSource<{','.join([str(c) for c in self.components])}>\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"WaveletSource<{len(self.components)}>\"\n",
    "\n",
    "\n",
    "class WaveletBlend(LiteBlend):\n",
    "    \"\"\"A blend composed of `WaveletSource`s\n",
    "    \"\"\"\n",
    "    def __init__(self, sources, observation):\n",
    "        # The weights used for the wavelet logL\n",
    "        self.weights = np.array([observation.weights]*len(observation.wavelets))\n",
    "        # The object used to apply the bspline to each scale\n",
    "        convolution = StarletConvolution(observation.scales)\n",
    "        self.convolution = convolution\n",
    "        # Convert a list of sources to wavelet sources\n",
    "        wavelet_sources = []\n",
    "        for source in sources:\n",
    "            wavelet_sources.append(WaveletSource(source.components, source.dtype, convolution))\n",
    "        super().__init__(wavelet_sources, observation)\n",
    "        \n",
    "        \n",
    "    def get_model(self, convolve=False, use_flux=False, stacked=False, transform=True):\n",
    "        \"\"\"Generate a model of the entire blend\"\"\"\n",
    "        if use_flux:\n",
    "            return super().get_model(convolve, use_flux)\n",
    "\n",
    "        # First combine the wavelet coefficients in all scales, in all bands, for all sources\n",
    "        model = np.zeros((self.observation.scales+1,)+self.bbox.shape, dtype=self.observation.images.dtype)\n",
    "        for source in self.sources:\n",
    "            model += source.get_model(bbox=self.bbox, stacked=True, transform=False)\n",
    "        \n",
    "        # Transform the wavelet coefficients at each scale, in each band\n",
    "        if transform:\n",
    "            model = self.convolution.transform_multiband(model)\n",
    "        # Recombine the wavelet coefficients into a real space image\n",
    "        if not stacked:\n",
    "            model = np.sum(model, axis=0)\n",
    "        # Convolve each band with the correct difference kernel\n",
    "        if convolve:\n",
    "            assert not stacked\n",
    "            model = self.observation.convolve(model)\n",
    "        return model\n",
    "        \n",
    "    def grad_logL(self):\n",
    "        \"\"\"Gradient of the likelihood wrt the unconvolved model\"\"\"\n",
    "        # Get the model at each scale\n",
    "        model = self.get_model(convolve=True, stacked=False, transform=True)\n",
    "        # Calculate the wavelet coefficients\n",
    "        wavelets = multiband_starlet_transform(\n",
    "            model, scales=self.observation.scales, generation=observation.gen)\n",
    "        \n",
    "        # Update the loss\n",
    "        self.loss.append(0.5 * -np.sum(self.weights * (self.observation.images - model)**2))\n",
    "        # Calculate the gradient wrt the model d(logL)/d(model)\n",
    "        _grad_logL = self.weights * (wavelets - self.observation.wavelets)\n",
    "        grad_logL = np.zeros(_grad_logL.shape, dtype=_grad_logL.dtype)\n",
    "        for scale, grad in enumerate(_grad_logL):\n",
    "            grad_logL[scale] = self.observation.convolve(grad, grad=True)\n",
    "        \n",
    "        #grad_logL = self.convolution.transform_multiband(grad_logL)\n",
    "        \n",
    "        return grad_logL\n",
    "    \n",
    "    def fit(self, max_iter, e_rel=1e-4, min_iter=1, resize=10, reweight=False):\n",
    "        \"\"\"Fit all of the parameters\n",
    "\n",
    "        See `LiteBlend` for a description of the parameters.\n",
    "        \"\"\"\n",
    "        it = self.it\n",
    "        while it < max_iter:\n",
    "            # Calculate the gradient wrt the on-convolved model\n",
    "            grad_logL = self.grad_logL()\n",
    "            # Update each component given the current gradient\n",
    "            for source in self.sources:\n",
    "                source.update(it, grad_logL)\n",
    "            # Check to see if any components need to be resized\n",
    "            if resize is not None and it > 0 and it % resize == 0:\n",
    "                for component in self.components:\n",
    "                    if hasattr(component, \"resize\"):\n",
    "                        component.resize()\n",
    "            # Stopping criteria\n",
    "            if it > min_iter and np.abs(self.loss[-1] - self.loss[-2]) < e_rel * np.abs(self.loss[-1]):\n",
    "                break\n",
    "            it += 1\n",
    "        self.it = it\n",
    "        if reweight:\n",
    "            weight_sources(self)\n",
    "        return it, self.loss[-1]\n",
    "\n",
    "def init_wavelet_source(center, observation, wavelets, convolution):\n",
    "    \"\"\"Initialize a wavelet source from the observation wavelets\n",
    "    \"\"\"\n",
    "    components = []\n",
    "    model_psf = observation.model_psf[0]\n",
    "    py = model_psf.shape[0]//2\n",
    "    px = model_psf.shape[1]//2\n",
    "    min_sed = 1e-20\n",
    "    sed_center = (slice(None), center[0], center[1])\n",
    "    \n",
    "    _, morph, bounds = prox_monotonic_mask(wavelets[0], 0, center, max_iter=0)\n",
    "    bbox = bounds_to_bbox(bounds)\n",
    "    if bbox.shape == (1, 1) and morph[bbox.slices][0,0] == 0:\n",
    "        morph = model_psf.copy()\n",
    "        morph = morph/np.max(morph)\n",
    "        bbox = Box(model_psf.shape, origin=(center[0]-py, center[1]-px))\n",
    "    else:\n",
    "         morph, bbox = project_morph_to_center(morph, center, bbox, observation.bbox[1:])\n",
    "    \n",
    "    all_morph = np.array([morph.copy()]*len(observation.wavelets))\n",
    "    \n",
    "    for morph in all_morph:\n",
    "        sed = observation.images[sed_center]\n",
    "        sed[sed<0] = 0\n",
    "        if np.all(sed==0):\n",
    "            sed[:] = min_sed\n",
    "\n",
    "        components.append(LiteComponent(center, observation.bbox[0] @ bbox, sed, morph))\n",
    "    \n",
    "    return WaveletSource(components, observation.images.dtype, convolution)\n",
    "\n",
    "def init_wavelet_sources(centers, observation):\n",
    "    \"\"\"Initialize all of the sources as wavelet sources\n",
    "    \"\"\"\n",
    "    wavelets = np.sum(multiband_starlet_transform(images, scales=scales, generation=1), axis=1)\n",
    "    wavelets[wavelets<0] = 0\n",
    "    \n",
    "    convolution = StarletConvolution(observation.scales)\n",
    "    \n",
    "    sources = []\n",
    "    for center in centers:\n",
    "        sources.append(init_wavelet_source(center, observation, wavelets, convolution))\n",
    "    return sources\n",
    "\n",
    "scales = 2\n",
    "observation.scales = scales\n",
    "observation.gen = 2\n",
    "observation.wavelets = multiband_starlet_transform(images, scales=scales, generation=observation.gen)\n",
    "\n",
    "# Wavelet sources work better with the FISTA optimization algorithm\n",
    "parameterize = fista_init\n",
    "\n",
    "sources = init_wavelet_sources(centers, observation)\n",
    "sources = parameterize_sources(sources, observation, parameterize)\n",
    "\n",
    "blend = WaveletBlend(sources, observation)\n",
    "%time blend.fit(100, min_iter=100)\n",
    "\n",
    "print(f\"{blend.it} iterations to a final -logL of {-blend.loss[-1]:.0f}\")\n",
    "\n",
    "display_multiresolution_residuals(images, mask, blend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
